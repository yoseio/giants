# _Devign_: Effective Vulnerability Identification by Learning Comprehensive Program Semantics via Graph Neural Networks

Yaqin Zhou Nanyang Technological University yaqinchou@gmail.com

Jingkai Siow Nanyang Technological University JINGKAI001@e.ntu.edu.sg

Shangqing Liu Nanyang Technological University shangqingliu666@gmail.com

Xiaoning Du Nanyang Technological University dxn0733@gmail.com

Yang Liu Nanyang Technological University yangliu@ntu.edu.sg

# Abstract

脆弱性の特定は、サイバーセキュリティにおいてソフトウェアシステムを攻撃から守るために極めて重要です。特に、修正を容易にするためには、ソースコード中の脆弱な関数を特定することが重要です。しかし、これは非常に困難で手間のかかる作業であり、専門的なセキュリティ知識も必要とされます。様々なコード表現グラフからの脆弱性パターンの手動定義に関する先行研究と、グラフニューラルネットワーク分野の最近の進展に着想を得て、私たちは、豊富なコード意味表現を学習することでグラフレベルの分類を行う汎用的なグラフニューラルネットワークベースのモデルである _Devign_ を提案します。本モデルには、新しい _Conv_ モジュールが含まれており、学習された豊富なノード表現からグラフレベルの分類に役立つ特徴を効率よく抽出します。このモデルは、高い複雑性と多様性をもつ実際の大規模オープンソースCプロジェクト4件に基づいて手動でラベル付けされたデータセットを用いて訓練されており、過去の研究で用いられてきた合成コードではなく実際のソースコードが使用されています。データセット上での広範な評価の結果、_Devign_ は、最先端手法よりも平均で10.51%高い精度および8.68%高いF1スコアを示し、_Conv_ モジュールを加えることで平均4.66%精度および6.37%F1が向上しました。

# 1 Introduction

近年、ソフトウェアの脆弱性の数は急速に増加しています。これはCVE（Common Vulnerabilities and Exposures）を通じて公表されたものだけでなく、専用コード内で内部的に発見されたものも含まれます。特に、オープンソースライブラリの普及は、脆弱性の増加要因であるだけでなく、その影響の拡大にもつながっています。これらの脆弱性の多くは安全でないコードが原因となっており、ソフトウェアシステムへの攻撃に悪用され、経済的・社会的に多大な損害を引き起こす可能性があります。

脆弱性の特定は、セキュリティ分野において非常に重要でありながら困難な課題です。静的解析[\[1](#page-8-0), [2\]](#page-8-1)、動的解析[\[3](#page-8-2)[–5](#page-8-3)]、およびシンボリック実行といった従来の手法に加え、補完的なアプローチとして機械学習を応用する試みが数多く進められてきました。これら初期の手法では[\[6](#page-8-4)[–8\]](#page-9-0)、人間の専門家によって手作業で作成された特徴やパターンが、機械学習アルゴリズムの入力として用いられ、脆弱性の検出が行われていました。しかし、脆弱性の根本的な原因は多様であり、

種類ごとの脆弱性[\[9\]](#page-9-1)やライブラリが存在するため、手作業で特徴量を作成して多数のライブラリに含まれるすべての脆弱性を分類するのは現実的ではありません。

既存の手法のユーザビリティを向上させ、人間の専門家による特徴抽出の多大な労力を回避するために、近年の研究では、より自動化された脆弱性特定のためにディープニューラルネットワークの可能性が探究されています。しかし、これらの研究はいずれも、実際のソースコードに存在する多様で複雑な脆弱性を特徴づける包括的なプログラム意味を学習する上で大きな制限があります。まず、学習手法に関しては、ソースコードを自然言語のような単なる平坦なシーケンスとして扱うか、部分的な情報だけで表現しています。しかし、ソースコードは実際には自然言語よりも構造的かつ論理的であり、抽象構文木(AST)、データフロー、制御フローなど異種の表現側面を持っています。さらに、脆弱性は時に複数の意味的側面から包括的に調査することを要する微妙な欠陥であることもあります。したがって、従来手法における設計上の欠点が、様々な脆弱性に対応する可能性を制限しています。次に、学習データに関しては、[11]のデータの一部はスタティックアナライザーによりラベル付けされており、実際には脆弱性でない高い割合の誤検知が含まれていました。また、[10]のようなものでは、コード中に「good」や「bad」といった表記を用いて脆弱なコードと非脆弱なコードを区別するほど単純な人工コードが用いられており、これは実際のコードの複雑さとは大きくかけ離れています。

この目的のために、私たちはファクトベースの脆弱性データに対応する新しいグラフニューラルネットワークに基づいたモデルと、複合的なプログラミング表現を提案します。これにより、古典的なプログラムコードのセマンティクス全体をエンコードし、さまざまな脆弱性の特徴を捉えることが可能となります。重要なイノベーションの一つは、新しい*Conv*モジュールです。これはゲート付きリカレントユニットから得られるグラフの異種ノード特徴を入力として受け取ります。*Conv*モジュールは、従来の畳み込み層や全結合層を活用することで、グラフレベルの分類のためにより粗い特徴を階層的に抽出します。さらに、ソースコードに対する複合プログラミング埋め込みの可能性と、提案するグラフニューラルネットワークモデルが脆弱性識別という困難なタスクに対して有効かどうかを検証するため、C言語で書かれた4つの人気かつ多様なライブラリから、手作業でラベル付けしたデータセットを作成しました。私たちはこのモデルを*Devign*（Deep Vulnerability Identification via Graph Neural Networks）と名付けました。

- 複合コード表現では、ASTを骨組みとして、プログラムの制御依存関係やデータ依存関係を異なるレベルで明示的に符号化し、それぞれの表現に対応した種類ごとの異質なエッジを備えた結合グラフに統合します。以前の研究では考慮されていなかったこの包括的な表現によって、できるだけ多様な種類やパターンの脆弱性を捉えることが容易になり、グラフニューラルネットワークによるより優れたノード表現の学習を可能にします。
- 私たちは、グラフレベルの分類のために*Conv*モジュールを備えたゲート付きグラフニューラルネットワークモデルを提案します。*Conv*モジュールはノード特徴量から階層的に学習し、グラフレベルの分類タスクにおいてより高次の表現を捉えます。
- 私たちは _Devign_ を実装し、4つの主要なCライブラリから収集した _手作業_ でラベル付けされたデータセット（_約600人時_ のコスト）を用いてその有効性を評価しました。2つのデータセットを、詳細情報とともに [\(https://sites.google.com/view/devign\)](https://sites.google.com/view/devign) で公開しています。結果として、_Devign_ はベースライン手法よりも平均で10.51%高い精度および8.68%高いF1スコアを達成しました。また、_Conv_ モジュールによって、平均で4.66%の精度向上と6.37%のF1向上が見られました。さらに、4つのプロジェクトから収集した最新の40件のCVEに _Devign_ を適用したところ、74.11%の精度を得ることができ、新たな脆弱性発見への実用性が示されました。

## 2 The _Devign_ Model

コードプロパティグラフを用いて手動で作成された脆弱性パターンは、すべての構文および依存関係のセマンティクスを統合することで、ソフトウェアの脆弱性を検出する最も効果的な手法の一つであることが証明されています[\[14\]](#page-9-6)。これに着想を得て、私たちは*Devign*を設計し、前述のプロセスをコードプロパティグラフ上で自動化し、グラフニューラルネットワークを用いて脆弱性パターンを学習できるようにしました[\[15\]](#page-9-7)。*Devign*のアーキテクチャは図[1,](#page-2-0)に示されており、以下の三つの連続したコンポーネントで構成されています。1) *Composite Code Semanticsのグラフ埋め込み層*は、関数の生のソースコードを総合的なプログラムセマンティクスを持つ統合グラフ構造にエンコードします。2) *Gated Graph Recurrent Layers*は、グラフ内の隣接ノードの情報を集約・伝達することでノードの特徴を学習します。3) *Convモジュール*は、グラフレベルでの予測のために意味のあるノード表現を抽出します。

<span id="page-2-0"></span>![](_page_2_Figure_0.jpeg)

Figure 1: _Devign_ のアーキテクチャ

#### 2.1 Problem Formulation

ほとんどの機械学習またはパターンベースの手法は、ソースファイルやアプリケーションという粗い粒度レベルで脆弱性を予測します。つまり、ソースファイルやアプリケーションが潜在的に脆弱かどうかを判断します [\[7](#page-9-8), [14,](#page-9-6) [10,](#page-9-2) [12](#page-9-3)]。本研究では、脆弱なコードを*関数レベル*で分析します。これは、脆弱性分析全体の中でも細かい粒度のレベルです。脆弱な関数の識別を二値分類問題として定式化します。つまり、生のソースコード内の与えられた関数が脆弱であるかどうかを判断することを学習します。データのサンプルを((c<sup>i</sup> , y<sup>i</sup>)|c<sup>i</sup> ∈ C, y<sup>i</sup> ∈ Y), i ∈ {1, 2, ... , n}と定義します。ここで、Cはコード内の関数の集合、Y = {0, 1}<sup>n</sup>はラベル集合（1が脆弱、0がそれ以外）、nはインスタンス数を表します。c<sup>i</sup>が関数であるため、これを多重辺グラフgi(V, X, A) ∈ Gとしてエンコードしていると仮定します（埋め込みの詳細はSection [2.2](#page-2-1)を参照）。mをV内のノード総数とすると、X ∈ R m×dは初期ノード特徴行列であり、それぞれの頂点v<sup>j</sup>はd次元の実数値ベクトルx<sup>j</sup> ∈ R dで表されます。A ∈ {0, 1}<sup>k</sup>×m×<sup>m</sup>は隣接行列で、kはエッジタイプの総数です。要素e p s,t ∈ Aが1であれば、ノードv<sub>s</sub>とv<sup>t</sup>がタイプpのエッジで接続されていること、0はそれ以外を示します。*Devign*の目的は、GからYへの写像、すなわちf : G 7→ Yを学習し、関数が脆弱かどうかを予測することです。予測関数fは、以下の損失関数を最小化することで学習できます。

$$
\min \sum_{i=1}^{n} \mathcal{L}(f(g_i(V, X, A), y_i|c_i)) + \lambda \omega(f) \tag{1}
$$

ここで、L(·)はクロスエントロピー損失関数、ω(·)は正則化項、λは調整可能な重みです。

#### 2.2 Graph Embedding Layer of Composite Code Semantics

図 [1,](#page-2-0) に示されているように、グラフ埋め込み層 EMB は、関数コード c<sup>i</sup> からモデルへの入力となるグラフデータ構造への写像となっています。

$$
g_i(V, X, A) = EMB(c_i), \forall i = \{1, ..., n\}
$$

（２）

このセクションでは、なぜ古典的なコード表現を利用し、それを特徴学習のために複合グラフへと埋め込むのか、その動機と方法について説明します。

#### 2.2.1 Classical Code Graph Representation and Vulnerability Identification

プログラム解析においては、テキストコードの奥にあるより深いセマンティクスを顕在化するために、様々なプログラム表現が利用される。古典的な概念としては、AST（抽象構文木）、制御フローグラフ、データフローグラフなどがあり、これらはソースコード内の異なるトークン間の構文的・意味的関係を捉えるものである。メモリリークなどの脆弱性の大半は、複合的なコードの意味論を総合的に考慮しないと検出が難しいほど微妙である[\[14](#page-9-6)]。例えば、AST単体では不安全な引数のみしか検出できないと報告されている[\[14\]](#page-9-6)。ASTと制御フローグラフを組み合わせることで、さらに2種類の脆弱性——すなわちリソースリークと一部のuse-after-free脆弱性もカバーできるようになる。さらに3つのコードグラフを統合することで、外部情報が必要な2つの例外を除くほとんどの種類の脆弱性を記述することが可能となる（すなわち、実行時特性に依存する競合状態や、プログラムの意図された設計の詳細がなければモデル化が難しい設計上のエラー）。

[\[14](#page-9-6)] では、脆弱性テンプレートをグラフトラバーサルの形で*手動で*作成していましたが、このアプローチは重要な洞察を示し、AST、制御フローグラフ、データフローグラフの特性を統合したデータ構造によって、より幅広い脆弱性パターンを学習できる可能性を実証しました。従来の3つのコード構造に加えて、ソースコードの自然なシーケンスも考慮しています。これは、近年のディープラーニングに基づく脆弱性検出の進展によって、その有効性が示されているためです [\[10](#page-9-2), [11\]](#page-9-4)。この手法は、独特なフラットな構造によって、コードトークン間の関係を「人間が読みやすい」形で捉えることができるため、従来の表現を補完する役割も果たします。

<span id="page-3-0"></span>![](_page_3_Figure_0.jpeg)

Figure 2: 整数オーバーフローを含むコードスニペットのグラフ表現

## 2.2.2 Graph Embedding of Code

次に、それぞれのコード表現の種類について簡単に紹介し、さまざまなサブグラフをどのようにして1つの統合グラフに表現するかを説明します。ここでは、Figure [2\(](#page-3-0)a) に示されている整数オーバーフローのコード例と、それを図示したグラフ表現（Figure [2\(](#page-3-0)b)）に従って解説します。

抽象構文木（AST）  
ASTはソースコードの順序付けられた木構造による表現です。通常、コードパーサがプログラムの基本的な構造を理解し、構文エラーを調べるための最初の段階の表現として使用されます。そのため、ASTは他の多くのコード表現を生成するための基礎となっており、本論文で用いられる4種類のコード表現のうち、ast のノード集合 V ast には他の3つすべてのコード表現のノードが含まれています。ルートノードから開始して、コードはコードブロック、ステートメント、宣言、式などへと分解され、最終的にはリーフノードを構成する基本的なトークンまで分解されます。主要なASTノードは図[2.](#page-3-0)に示されています。すべての四角はASTノードであり、1行目に特定のコードが示され、ノードの種類が注釈されています。青色のボックスはASTの葉ノード、紫色の矢印は子・親の*AST*関係を表します。

Control Flow Graph (CFG) CFGは、プログラムの実行中に通りうるすべての経路を表現します。経路の選択肢は、条件文、例えば _if_、_for_、_switch_ 文などによって決定されます。CFGにおいて、ノードは文や条件を表し、それらは有向辺で接続されており、制御の移動を示します。_CFG_ の辺は、図[2.](#page-3-0) で緑色の破線矢印として強調されています。特に、プログラムの流れはエントリーから始まり、エグジットで終わり、_if_ 文では2つの異なる経路に分岐します。

Data Flow Graph (DFG) DFGは、CFG全体で変数の使用状況を追跡します。データフローは変数に着目しており、いかなるデータフローも特定の変数へのアクセスまたは変更を伴います。DFGのエッジは、同じ変数に対してその後に行われるアクセスや変更を表します。これはFigure [2](#page-3-0)でオレンジ色の二重矢印として示されており、関与する変数がエッジ上に注釈されています。例えば、パラメータbは*if*条件文と代入文の両方で使用されています。

Natural Code Sequence (NCS)  
ソースコードの自然な順序を符号化するために、*NCS*エッジを用いてAST内の隣接するコードトークンを接続します。このようなエンコーディングの主な利点は、ソースコードの順序が反映するプログラミングロジックを保持できる点です。*NCS*エッジは図[2,](#page-3-0)で赤い矢印で示されており、ASTのすべての葉ノードを接続しています。

したがって、関数 c<sup>i</sup> は、同じノード集合 V = V ast を共有する4種類の部分グラフ（または4種類のエッジ）を持つ合同グラフ g で表すことができます。図 [\(2\)](#page-3-0) に示すように、各ノード v ∈ V には _Code_ と _Type_ の2つの属性があります。_Code_ には、v で表されるソースコードが格納され、v のタイプはそのタイプ属性を示します。初期ノード表現 x<sup>v</sup> には、この2つの属性が反映される必要があります。したがって、_Code_ は、プロジェクト内の全ソースコードファイルから構築したコードコーパスを用いて、事前学習済みの word2vec モデルでエンコードし、_Type_ はラベルエンコーディングで表現します。2つのエンコーディングを連結することで、初期ノード表現 xv とします。

### 2.3 Gated Graph Recurrent Layers

グラフニューラルネットワークの主要なアイデアは、近傍集約を通じてノードの表現をローカルな近傍から埋め込むことにあります。近傍情報の集約手法の違いに基づき、グラフ畳み込みネットワーク、GraphSAGE、ゲート付きグラフリカレントネットワークおよびその派生手法などがあります。私たちはノード埋め込みを学習するためにゲート付きグラフリカレントネットワークを選択しました。これは、他の二つよりも深く学習することが可能であり、意味情報とグラフ構造の両方を持つ私たちのデータにより適しているからです。

埋め込みグラフ gi(V, X, A) が与えられたとき、各ノード v<sup>j</sup> ∈ V に対して、ノード状態ベクトル h (1) <sup>j</sup> <sup>∈</sup> <sup>R</sup> z , z ≥ d を初期アノテーションを用いて初期化します。これは、x<sup>j</sup> を最初の次元にコピーし、アノテーションサイズより大きい隠れ状態を許容するため追加の 0 でパディングすることによって実現されます。すなわち、h 1 <sup>j</sup> = [x ⊤ j , 0] <sup>⊤</sup> となります。T を近傍集約のための総タイムステップ数とします。グラフ全体に情報を伝播させるため、各タイムステップ t ≤ T では、すべてのノードがエッジの種類や方向に依存して情報をエッジ経由でやり取りします（これはエッジタイプごとに定義される隣接行列 A の p 番目の隣接行列 A<sup>p</sup> で表されます。定義より、隣接行列の数はエッジタイプの数となります）。

$$
a_{j,p}^{(t-1)} = A_p^{\top} \left( W_p \left[ h_1^{(t-1)\top}, \dots, h_m^{(t-1)\top} \right] + b \right)
$$

（3）

ここで、W<sup>p</sup> ∈ R z×z は学習される重みであり、b はバイアスです。具体的には、ノード v<sup>j</sup> の新しい状態 aj,p は、エッジタイプ p における隣接行列 A<sup>p</sup>上で定義されたすべての隣接ノードの情報を集約することによって計算されます。残りのステップはゲート付きリカレントユニット（GRU）で構成されており、すべてのタイプからの情報とノード v、および前の時刻の情報を統合して、現在のノードの隠れ状態 h (t) i,v を得ます。

$$
h_j^{(t)} = GRU(h_j^{(t-1)}, AGG(\{a_{j,p}^{(t-1)}\}_{p=1}^k))
$$

\n(4)

ここで、AGG(·) は集約関数を表しており、異なるエッジタイプからの情報を集約して次のタイムステップのノード埋め込み h(t) を計算するために {MEAN, MAX, SUM, CONCAT} のいずれかの関数を利用できます。実装では SUM 関数を使用しています。上記の伝播処理は T タイムステップにわたって繰り返され、最後のタイムステップにおける状態ベクトル H(T)<sup>i</sup> = {h(T)j} m<sup>j</sup>=1 がノード集合 V の最終的なノード表現行列となります。

#### 2.4 The Conv Layer

ゲーテッドグラフリカレントレイヤーから生成されたノード特徴量は、ノード、リンク、グラフレベルの予測など、あらゆる予測レイヤーへの入力として利用でき、その後、モデル全体をエンドツーエンドで学習させることが可能です。本研究の課題では、関数c<sup>i</sup>が脆弱かどうかを判定するグラフレベルの分類タスクを行う必要があります。グラフ分類の標準的なアプローチとしては、生成されたノード埋め込みを全体で集約し、たとえば線形加重和を用いてすべての埋め込みをフラットに加算する方法[\[15\],](#page-9-7) [19\]](#page-9-12)が一般的であり、式[\(5\)](#page-4-0)に示されています。

<span id="page-4-0"></span>

$$
\tilde{y}_i = Sigmoid\bigg(\sum MLP([H_i^{(T)}, x_i])\bigg) \tag{5}
$$

この式は、MLPによって生成された$[H_i^{(T)}, x_i]$の組合せから、Sigmoid関数を通じて$\tilde{y}_i$を算出していることを示しています。

ここで、シグモイド関数は分類に使用され、MLPはH (T) iとx<sup>i</sup>の連結をR<sup>m</sup>ベクトルに写像する多層パーセプトロン（MLP）を指します。このような手法は、グラフ全体にわたる効果的な分類を妨げます [\[20,](#page-9-13) [21\]](#page-9-14)。

このようにして、*Conv*モジュールは、現在のグラフレベルのタスクに関連するノードや特徴量の集合を選択するように設計されています。先行研究[\[21\]](#page-9-14)では、グラフの畳み込み層の後にSortPooling層を用いて、固定の順序がないグラフのノード特徴量を一貫した順序で並べ替え、伝統的なニューラルネットワークをその後に適用して、グラフに符号化された豊富な情報を特徴付ける有用な特徴量を抽出することが提案されています。本研究の問題設定では、それぞれのコード表現グラフが隣接行列に符号化された独自のノード順序と接続関係を持っており、ノードの特徴量は複数のチャネルから特徴をソートする必要があるグラフ畳み込みネットワークではなく、ゲート付きリカレントグラフ層を通じて学習されます。したがって、私たちは、グラフレベルのタスクに関連する特徴量をより効果的に予測するために、1次元畳み込みと全結合ニューラルネットワークを直接適用します[1](#page-4-1)。σ(·)を最大プーリング付きの1次元畳み込み層と定義します。

$$
\sigma(\cdot) = MAXPOOL(Relu(CONV(\cdot)))\tag{6}
$$

lを畳み込み層の数とすると、*Conv*モジュールは次のように表すことができます。

$$
Z_i^{(1)} = \sigma([H_i^{(T)}, x_i]), \dots, Z_i^{(l)} = \sigma(Z_i^{(l-1)})
$$

\n(7)

$$
Y_i^{(1)} = \sigma(H_i^{(T)}), \dots, Y_i^{(l)} = \sigma(Y_i^{(l-1)})
$$

\n(8)

$$
\tilde{y}_i = Sigmoid\big(AVG(MLP(Z_i^{(l)}) \odot MLP(Y_i^{(l)}))\big) \tag{9}
$$

まず、連結された [H (T) i , x<sup>i</sup> ] に従来の1次元畳み込み層を、最終ノード特徴量 H (T) i に全結合層をそれぞれ適用します。その後、両者の出力に対してペアワイズな積を取り、その結果得られたベクトルに平均集約を行い、最後に予測を行います。

<span id="page-4-1"></span><sup>1</sup>また、ソートされたノードをAST順に並べてLSTMやBiLSTM（アテンション機構の有無両方）も試しましたが、全体的には畳み込みネットワークが最も良い結果を示しました。

<span id="page-5-0"></span>

この表は、4つの主要なオープンソースプロジェクト（Linux Kernel、QEMU、Wireshark、FFmpeg）におけるセキュリティ関連のコミット数や、グラフ化した脆弱性と非脆弱性の数など、様々な統計データを示しています。一番右の列は、各指標の合計値を示しています。

Table 1: データセットの概要

# 3 Evaluation

私たちは、最先端の脆弱性発見手法と比較して*Devign*の利点を評価し、次の疑問を明らかにすることを目的としています。

Q1 私たちの*Devign*は、他の学習ベースの脆弱性識別手法と比べてどのような特徴がありますか？Q2 畳み込みモジュールを搭載した*Devign*は、グラフレベルの分類タスクにおいて、式[\(5\)](#page-4-0)の単純な総和を用いた*Ggrn*と比較して、どのような違いがありますか？

Q3 *Devign*は各種コード表現（例えば、一種類の情報のみを含む単一エッジグラフ）から学習できますか？また、複合グラフ（例えば、すべての種類のコード表現を含むグラフ）を用いた*Devign*モデルは、単一エッジグラフごとのモデルと比べてどのような違いがありますか？

Q4 現実のシナリオでは、データセットにおける脆弱な関数の割合が非常に低いという極端に不均衡な状況ですが、_Devign_ は一部の静的解析ツールと比べてより良いパフォーマンスを発揮することができますか？

Q5 *Devign*は、CVEを通じて公開された最新の脆弱性に対してどのような性能を示しますか？

## 3.1 Data Preparation

高品質な脆弱な関数のデータセットを入手することは、専門的な知識が求められるため、決して容易ではありません。[\[12\]](#page-9-3) では脆弱な関数のデータセットが公開されていますが、ラベルは統計解析ツールによって生成されており、正確性には欠けています。また、[\[22](#page-9-15)] で使用されている他の潜在的なデータセットも利用できません。本研究では、産業界のパートナーの支援のもと、セキュリティの専門チームを編成して、ゼロからデータの収集とラベリングを行いました。生の関数を収集するだけでなく、それぞれの関数に対してグラフ表現を生成し、さらにグラフ内の各ノードの初期表現も生成する必要があります。詳細な手順については以下で説明します。

Raw Data Gathering  
_Devign_ の脆弱性パターンを学習する能力を評価するために、私たちは開発者の間で人気があり、機能が多様である4つの大規模なC言語オープンソースプロジェクト（Linux Kernel、QEMU、Wireshark、FFmpeg）から収集した手作業でラベル付けされた関数に基づいて評価を行います。

データラベリングの効率化と品質確保のために、まずセキュリティ関連のコミットを収集し、それらを脆弱性修正コミットまたは非脆弱性修正コミットとしてラベル付けしました。次に、ラベル付けされたコミットから脆弱または非脆弱な関数を直接抽出しました。脆弱性修正コミット（VFC）は、潜在的な脆弱性を修正するコミットであり、これらからコミットが行われる前のバージョンのソースコードから脆弱な関数を抽出できます。一方、非脆弱性修正コミット（non-VFC）は、脆弱性を修正しないコミットであり、同様に修正前のソースコードから非脆弱な関数を抽出することができます。コミットの収集には [\[23](#page-9-16)] で提案された手法を採用しました。これは以下の2つのステップから成ります。1) _コミットのフィルタリング_。脆弱性関連のコミットはごくわずかしか存在しないため、DoS や injection などのセキュリティ関連キーワードに一致しないメッセージを持つセキュリティ非関連のコミットは除外します。残ったものはセキュリティ関連の可能性が高く、手動でラベル付けします。2) _手動ラベリング_。4人の専門的なセキュリティ研究者チームが合計 _600人時_ をかけ、データの2回のラベリングとクロス検証を実施しました。

VFC または non-CFC が与えられた場合、変更された関数にもとづいて、コミットが適用される前のこれらの関数のソースコードを抽出し、ラベルを適切に割り当てます。

Graph Generation  
私たちは、コードプロパティグラフに基づくC/C++用のオープンソースコード解析プラットフォームであるJoern [\[14\]](#page-9-6) を利用して、データセット内のすべての関数のASTとCFGを抽出します。Joern内の一部のコンパイルエラーや例外のため、私たちは関数の一部にしかASTとCFGを取得できません。ASTやCFGが得られなかった関数や、ASTとCFGに明らかなエラーがある関数は除外しています。元々のDFGのエッジには関連する変数がラベル付けされており、これがエッジの種類を著しく増やし、埋め込みグラフを複雑にしてしまうため、DFGの代わりに他の三つの関係、_LastRead (DFG_R)_、*LastWrite (DFG_W)*を用いています。

| Method                                                                   | Linux Kernel            |                                  | QEMU                             |                                  | Wireshark                        |                                  | FFmpeg                           |                                  | Combined                         |                                  | Max Diff |                                                                      | Avg Diff |                              |
| ------------------------------------------------------------------------ | ----------------------- | -------------------------------- | -------------------------------- | -------------------------------- | -------------------------------- | -------------------------------- | -------------------------------- | -------------------------------- | -------------------------------- | -------------------------------- | -------- | -------------------------------------------------------------------- | -------- | ---------------------------- |
|                                                                          | ACC                     |                                  | ACC                              |                                  | ACC                              |                                  | ACC                              |                                  | ACC                              |                                  | ACC      |                                                                      | ACC      |                              |
|                                                                          | F1                      |                                  | F1                               |                                  | F1                               |                                  | F1                               |                                  | F1                               |                                  | F1       |                                                                      | F1       |                              |
| Metrics + Xgboost<br>3-layer BiLSTM<br>3-layer BiLSTM + Att 75.63<br>CNN | 67.17<br>67.25<br>70.72 | 79.14<br>80.41<br>82.66<br>79.55 | 59.49<br>57.85<br>65.79<br>60.47 | 61.27<br>57.75<br>59.92<br>59.29 | 70.39<br>69.08<br>74.50<br>70.48 | 61.31<br>55.61<br>58.52<br>58.15 | 67.17<br>53.27<br>61.71<br>53.42 | 63.76<br>69.51<br>66.01<br>66.58 | 61.36<br>59.40<br>69.57<br>63.36 | 63.76<br>65.62<br>68.65<br>60.13 | 8.54     | 14.84 11.80 10.30<br>16.48 15.32 14.04<br>13.15<br>16.16 13.78 11.72 | 5.97     | 8.71<br>8.78<br>7.41<br>9.82 |
| Ggrn (AST)                                                               | 72.65                   | 81.28                            | 70.08                            | 66.84                            | 79.62                            | 64.56                            | 63.54                            | 70.43                            | 67.74                            | 64.67                            | 6.93     | 8.59                                                                 | 4.69     | 5.01                         |
| Ggrn (CFG)                                                               | 78.79                   | 82.35                            | 71.42                            | 67.74                            | 79.36                            | 65.40                            | 65.00                            | 71.79                            | 70.62                            | 70.86                            | 4.58     | 5.33                                                                 | 2.38     | 2.93                         |
| Ggrn (NCS)                                                               | 78.68                   | 81.84                            | 72.99                            | 69.98                            | 78.13                            | 59.80                            | 65.63                            | 69.09                            | 70.43                            | 69.86                            | 3.95     | 8.16                                                                 | 2.24     | 4.45                         |
| Ggrn (DFG_C)                                                             | 70.53                   | 81.03                            | 69.30                            | 56.06                            | 73.17                            | 50.83                            | 63.75                            | 69.44                            | 65.52                            | 64.57                            | 9.05     | 17.13                                                                | 6.96     | 10.18                        |
| Ggrn (DFG_R)                                                             | 72.43                   | 80.39                            | 68.63                            | 56.35                            | 74.15                            | 52.25                            | 63.75                            | 71.49                            | 66.74                            | 62.91                            | 7.17     | 16.72                                                                | 6.27     | 9.88                         |
| Ggrn (DFG_W)                                                             | 71.09                   | 81.27                            | 71.65                            | 65.88                            | 72.72                            | 51.04                            | 64.37                            | 70.52                            | 63.05                            | 63.26                            | 9.21     | 16.92                                                                | 6.84     | 8.17                         |
| Ggrn (Composite)                                                         | 74.55                   | 79.93                            | 72.77                            | 66.25                            | 78.79                            | 67.32                            | 64.46                            | 70.33                            | 70.35                            | 69.37                            | 5.12     | 6.82                                                                 | 3.23     | 3.92                         |
| Devign (AST)                                                             | 80.24                   | 84.57                            | 71.31                            | 65.19                            | 79.04                            | 64.37                            | 65.63                            | 71.83                            | 69.21                            | 69.99                            | 3.95     | 7.88                                                                 | 2.33     | 3.37                         |
| Devign (CFG)                                                             | 80.03                   | 82.91                            | 74.22                            | 70.73                            | 79.62                            | 66.05                            | 66.89                            | 70.22                            | 71.32                            | 71.27                            | 2.69     | 3.33                                                                 | 1.00     | 2.33                         |
| Devign (NCS)                                                             | 79.58                   | 81.41                            | 72.32                            | 68.98                            | 79.75                            | 65.88                            | 67.29                            | 68.89                            | 70.82                            | 68.45                            | 2.29     | 4.81                                                                 | 1.46     | 3.84                         |
| Devign (DFG_C)                                                           | 78.81                   | 83.87                            | 72.30                            | 70.62                            | 79.95                            | 66.47                            | 65.83                            | 70.12                            | 69.88                            | 70.21                            | 3.75     | 3.43                                                                 | 2.06     | 2.30                         |
| Devign (DFG_R)                                                           | 78.25                   | 80.33                            | 73.77                            | 70.60                            | 80.66                            | 66.17                            | 66.46                            | 72.12                            | 71.49                            | 70.92                            | 3.12     | 4.64                                                                 | 1.29     | 2.53                         |
| Devign (DFG_W)                                                           | 78.70                   | 84.21                            | 72.54                            | 71.08                            | 80.59                            | 66.68                            | 67.50                            | 70.86                            | 71.41                            | 71.14                            | 2.08     | 2.69                                                                 | 1.27     | 1.77                         |
| Devign (Composite)                                                       | 79.58                   | 84.97                            | 74.33                            | 73.07                            | 81.32                            | 67.96                            | 69.58                            | 73.55                            | 72.26                            | 73.26                            | -        | -                                                                    | -        | -                            |

Table 2: 分類精度とF1スコア（パーセント表示）：最も右の2列には、_Devign_ モデル（複合コード表現を使用）、すなわち _Devign_ (Composite) と比較した場合の、精度とF1スコアにおける最大および平均の相対的な差が示されています。

そして _ComputedFrom (DFG_C)_ [\[24\]](#page-9-17) を使用して、グラフ埋め込みにより適応できるようにしています。_DFG_R_ は、各変数が出現した直後の最後の読み取りを表します。各出現箇所はASTの葉ノードから直接認識できます。_DFG_W_ は、各変数が出現した直後の最後の書き込みを表します。同様に、これらの注釈も葉ノードの変数に付与します。_DFG_C_ は変数のソースを決定します。代入文では、左辺（lhs）の変数に右辺（rhs）の式によって新しい値が割り当てられます。DFG_Cは、lhs変数とrhsの各変数との関係を捉えます。

さらに、計算効率を考慮してノードサイズが500を超える関数を除外しています。これは全体の15%に相当します。データセットの統計情報については、表[1.](#page-5-0)にまとめています。

## 3.2 Baseline Methods

性能比較では、_Devign_ を最先端の機械学習ベースの脆弱性予測手法および、分類のために線形加重和を用いたゲート付きグラフリカレントネットワーク（_Ggrn_）と比較します。

Metrics + Xgboost [\[22\]](#page-9-15): 各関数ごとに、Joernを用いて合計4つの複雑性メトリクスと11の脆弱性メトリクスを収集し、分類にはXgboostを利用しました。ここでは学習ベースではなく、脆弱である可能性をランク付けするためのヒューリスティックで設計された手法であるため、提案されたビニングおよびランキング手法は使用していません。最適なパラメータの探索にはBayes Optimization [\[25\]](#page-10-0) を利用しました。

3層のBiLSTM [\[10](#page-9-2)]：ソースコードを自然言語として扱い、トークナイズされたコードをWord2vecで事前学習された初期埋め込みとともに双方向LSTMに入力します。ここでは最良の性能を得るために、3層の双方向モデルを実装しました。

3層BiLSTM + Att: これは、アテンションメカニズム [\[26\]](#page-10-1) を用いて改良された [\[10\]](#page-9-2) のバージョンです。

CNN [\[11\]](#page-9-4): [\[10\]](#page-9-2)と同様に、ソースコードを自然言語として扱い、コードトークンの初期埋め込みを取得するためにbag of wordsを利用し、その後、CNNに入力して学習します。

## 3.3 Performance Evaluation

_Devign_ の設定  
埋め込み層では、初期ノード表現のための word2vec の次元数を 100 に設定しています。ゲーティッドグラフリカレント層では、隠れ状態の次元数を 200、タイムステップ数を 6 に設定しています。_Devign_ の _Conv_ パラメータに関しては、最初の畳み込み層には ReLU 活性化関数付きの (1, 3) フィルタを適用し、その後に (1, 3) フィルタと (1, 2) ストライドの最大プーリング層を配置します。2 番目の畳み込み層には (1, 1) フィルタを使い、(2, 2) フィルタと (1, 2) ストライドの最大プーリング層を続けます。最適化手法には Adam オプティマイザを用い、学習率 0.0001、バッチサイズ 128、また過学習を防ぐために L2 正則化を利用します。各データセットはランダムにシャッフルし、75% を分割して使用しています。

| Method                      | Cppcheck<br>ACC | F1   | Flawfinder<br>ACC | F1   | CXXX<br>ACC            | F1<br>ACC | F1    | ACC   | 3-layer BiLSTM 3-layer BiLSTM + Att<br>F1 | ACC   | CNN<br>F1         | ACC   | Devign (Composite)<br>F1 |
| --------------------------- | --------------- | ---- | ----------------- | ---- | ---------------------- | --------- | ----- | ----- | ----------------------------------------- | ----- | ----------------- | ----- | ------------------------ |
| Linux                       | 75.11           | 0    |                   |      | 78.46 12.57 19.44 5.07 | 18.25     | 13.12 | 8.79  | 16.16                                     |       | 29.03 15.38 69.41 |       | 24.64                    |
| QEMU                        | 89.21           | 0    | 86.24             | 7.61 | 33.64 9.29             | 29.07     | 15.54 | 78.43 | 10.50                                     |       | 75.88 18.80 89.27 |       | 41.12                    |
| Wireshark 89.19 10.17 89.92 |                 |      |                   | 9.46 | 33.26 3.95             | 91.39     | 10.75 | 84.90 | 28.35                                     | 86.09 | 8.69              | 89.37 | 42.05                    |
| FFmpeg                      | 87.72           | 0    |                   |      | 80.34 12.86 36.04 2.45 | 11.17     | 18.71 | 8.98  | 16.48                                     |       | 70.07 31.25 69.06 |       | 34.92                    |
| Combined 85.41              |                 | 2.27 |                   |      | 85.65 10.41 29.57 4.01 | 9.65      | 16.59 | 15.58 | 16.24                                     |       | 72.47 17.94 75.56 |       | 27.25                    |

この表は、各種の手法について異なるデータセットで検証した際の、F1スコアや精度（ACC）を比較したものです。それぞれの行はLinux、QEMU、Wireshark、FFmpeg、全体を統合したCombinedというデータセットに対応しています。列にはCppcheck、Flawfinder、CXXX、3-layer BiLSTMやCNN、Devignなど複数の手法が記載されており、それぞれの手法の性能を数値で示しています。これにより、各手法がどの程度の精度やF1スコアを達成できているかを分かりやすく比較できます。

<span id="page-7-0"></span>表3：不均衡な設定下での分類精度およびF1スコアのパーセンタイル

トレーニングにはそのうちの75%を、残りの25%を検証に使用します。私たちのモデルは、Nvidia Graphics Tesla M40およびP40上でトレーニングしており、アーリーストッピングには100エポックのパティエンスを設定しています。

Results Analysis  
私たちは性能を測定するために*accuracy*と*F1 score*を用いています。表[3.3](#page-7-0)にすべての実験結果をまとめています。まず、Q1に関する結果、すなわち他の学習ベースの手法と比較した*Devign*の性能について分析します。ベースライン手法、*Ggrn*および複合コード表現を用いた*Devign*の結果から、*Ggrn*と*Devign*の両方がすべてのデータセットでベースライン手法を大きく上回っていることが分かります。特に、すべてのベースライン手法と比べて、*Devign*による相対精度の向上は平均で10.51%、QEMUデータセットでも最低8.54%となっています。また、_Devign_（Composite）はF1スコアにおいても4つのベースライン手法を上回っており、平均の相対的なF1スコアの向上は8.68%、各データセット（Linux Kernel、QEMU、Wirshark、FFmpeg、およびCombined）における最小の相対向上率はそれぞれ2.31%、11.80%、6.65%、4.04%、4.61%となっています。Linuxがコーディングスタイルのベストプラクティスに従っているため、*Devign*によるF1スコア84.97はすべてのデータセットの中で最も高い値となっています。*したがって、*Devign*はグラフに包括的なセマンティクスを符号化することで、最先端の脆弱性識別手法よりも有意に高い性能を発揮します。*

次に、_Devign_ が _Ggrn_ に対してどれだけ性能向上を果たしているかというQ2の回答について検討します。まず、複合コード表現でのスコアを見てみます。すべてのデータセットにおいて、_Devign_ は _Ggrn_ よりも高い精度（平均3.23%向上）を達成しており、最大の精度向上はFFmpegデータセットで5.12%となっています。また、_Devign_ はF1スコアでも _Ggrn_ より高く、平均で3.92%の向上が見られ、最大のF1スコア向上はQEMUデータセットで6.82%となっています。さらに、それぞれの単一コード表現でのスコアも確認したところ、おおむね同様の結論が得られ、一般的に _Devign_ は _Ggrn_ を大きく上回っています。最大の精度向上はDFG_Wエッジで9.21%、最大のF1スコア向上はDFG_Cで17.13%です。*全体として、*Devign* が *Ggrn* と比べて平均で4.66%の精度向上、6.37%のF1スコア向上を示しており、これはConvモジュールがグラフレベル予測のためにより関連性の高いノードや特徴を抽出できていることを示しています。*

次に、Q3の結果を確認し、_Devign_ がさまざまなタイプのコード表現を学習できるかどうか、そして複合グラフでの性能について検証します。驚くべきことに、単一エッジのグラフから学習された結果は、_Ggrn_ と _Devign_ の両方で非常に有望なものであることがわかりました。_Ggrn_ については、特定のタイプのエッジでは複合グラフよりも精度がやや高い場合があり、例えば CFG や NCS グラフは FFmpeg と combined データセットでより良い結果を示しています。_Devign_ では、精度に関して Linux データセットを除けば、複合グラフの表現はどの単一エッジグラフよりも全体的に優れており、その差は0.11%から3.75%の範囲でした。F1スコアに関しては、複合グラフによる改善は平均で2.69%、すべてのテストで0.4%から7.88%の範囲となっています。_要約すると、複合グラフは_ Devign _に単一エッジグラフよりも優れた予測モデルの学習をもたらします。_

Q4の実際の不均衡データセットにおける静的アナライザとの比較について答えるために、大規模な産業レベルの分析[\[23](#page-9-16)]に従い、テストデータをランダムにサンプリングして脆弱な関数が10%となる不均衡なデータセットを作成しました。よく知られているオープンソースの静的アナライザCppcheck、Flawfinder、そして法的な理由から名前を伏せた商用ツールCXXXと比較を行いました。結果はTable に示されており、我々のアプローチはすべての静的アナライザを大きく上回り、F1スコアで27.99高い値を記録しています。一方、静的アナライザはほとんどの脆弱な関数を見逃し、誤検知も多い傾向があります。例えば、Cppcheckは4つの単一プロジェクトデータセットのうち3つで脆弱性を1件も検出できませんでした。

最後に、Q5で問われている最新の公開された脆弱性について回答するため、各プロジェクトの最新10件のCVEを収集し、*Devign*がゼロデイ脆弱性の特定に応用可能かどうかを確認しました。40件のCVEのコミット修正に基づき、合計で112個の脆弱な関数を抽出しました。_これらの関数を学習済みの_ Devign *モデルに入力したところ、平均精度74.11%を達成しました。これは、*Devign*が実際のアプリケーションにおいて新たな脆弱性を発見する可能性を示しています。*

# 4 Related Work

ディープラーニングの成功は、研究者たちに対し、ソースコード上での脆弱性発見をより自動化されたソリューションへ適用しようという動機を与えています [\[12,](#page-9-3) [10,](#page-9-2) [11](#page-9-4)]。最近の研究 [\[10,](#page-9-2) [12,](#page-9-3) [11\]](#page-9-4) では、ソースコードを平坦な自然言語のシーケンスとして扱い、脆弱性検出における自然言語処理技術の可能性を探っています。たとえば、[\[12](#page-9-3), [10\]](#page-9-2) ではLSTM/BiLSTMニューラルネットワークを基盤とするモデルが構築されており、[\[11\]](#page-9-4) では代わりにCNNの使用が提案されています。

上述のモデルがコード中の論理や構造を表現する際の制約を克服するために、多くの研究では木構造やグラフ構造のような、より構造的なニューラルネットワークを様々なタスクで応用しようと試みられてきました。例えば、[15]ではプログラム検証のための論理式をゲーテッドグラフ再帰ニューラルネットワークを用いて生成する手法が提案されており、[24]では変数名の予測や変数の誤使用の予測を目的としています。[28]では、バイナリコードの類似性検出のためにGeminiを提案し、バイナリコード内の関数を属性付き制御フローグラフで表現し、グラフ埋め込みを学習するためにStructure2vecを入力としています。これらの研究とは異なり、本研究は脆弱性の特定を目的とし、できる限り多くの種類の脆弱性を表現できる包括的なコード表現を取り入れています。また、本研究では、[15]で用いられているゲーテッドグラフ再帰層を採用し、ノードの注釈などノードの意味情報や構造的特徴の両方を考慮しました。これらはどちらも脆弱性発見において重要です。Structure2vecは主に構造的特徴の学習に焦点を当てています。[24]がゲーテッドグラフ再帰ネットワークを変数予測に適用しているのに対し、本研究では制御フローグラフを合成グラフに明示的に組み込み、効率的なグラフレベルの分類のために*Conv*モジュールを提案しています。

## 5 Conclusion and Future Work

私たちは、新しい脆弱性識別モデル _Devign_ を紹介します。このモデルは、ソースコードの関数を複数の構文的および意味的な表現から統合グラフ構造にエンコードし、その複合グラフ表現を活用して、脆弱なコードを効果的に発見する方法を学習できます。これは、実際のオープンソースプロジェクトにおける機械学習ベースの脆弱な関数発見で新たな最先端成果を達成しました。興味深い将来の課題としては、プログラムスライシングの統合による大きな関数からの効率的な学習、このモデルを他のプロジェクト間で脆弱性検出に適用すること、人間が読みやすいまたは説明可能な脆弱性評価の生成などが挙げられます。

## References

- <span id="page-8-0"></span>[1] Z. Xu, B. Chen, M. Chandramohan, Y. Liu, and F. Song, "Spain: security patch analysis for binaries towards understanding the pain and pills," in _Proceedings of the 39th International Conference on Software Engineering_. IEEE Press, 2017, pp. 462–472.
- <span id="page-8-1"></span>[2] M. Chandramohan, Y. Xue, Z. Xu, Y. Liu, C. Y. Cho, and H. B. K. Tan, "Bingo: Crossarchitecture cross-os binary search," in _Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering_. ACM, 2016, pp. 678–689.
- <span id="page-8-2"></span>[3] Y. Li, Y. Xue, H. Chen, X. Wu, C. Zhang, X. Xie, H. Wang, and Y. Liu, "Cerebro: contextaware adaptive fuzzing for effective vulnerability detection," in _Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering_. ACM, 2019, pp. 533–544.
- [4] H. Chen, Y. Xue, Y. Li, B. Chen, X. Xie, X. Wu, and Y. Liu, "Hawkeye: Towards a desired directed grey-box fuzzer," in _Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security_. ACM, 2018, pp. 2095–2108.
- <span id="page-8-3"></span>[5] Y. Li, B. Chen, M. Chandramohan, S.-W. Lin, Y. Liu, and A. Tiu, "Steelix: program-state based binary fuzzing," in _Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering_. ACM, 2017, pp. 627–637.
- <span id="page-8-4"></span>[6] S. Neuhaus, T. Zimmermann, C. Holler, and A. Zeller, "Predicting vulnerable software components," in _Proceedings of the 14th ACM Conference on Computer and Communications Security_, ser. CCS '07. New York, NY, USA: ACM, 2007, pp. 529–540. [Online]. Available: <http://doi.acm.org/10.1145/1315245.1315311>
- <span id="page-9-8"></span>[7] V. H. Nguyen と L. M. S. Tran による "Predicting vulnerable software components with dependency graphs" は、_Proceedings of the 6th International Workshop on Security Measurements and Metrics_、MetriSec '10 の一環として発表されました。New York, NY, USA: ACM、2010年、pp. 3:1–3:8。 [オンライン]. 入手先: <http://doi.acm.org/10.1145/1853919.1853923>
- <span id="page-9-0"></span>[8] Y. Shin, A. Meneely, L. Williams, and J. A. Osborne, "Evaluating complexity, code churn, and developer activity metrics as indicators of software vulnerabilities," _IEEE Trans. Softw. Eng._, vol. 37, no. 6, pp. 772–787, Nov. 2011. [Online]. Available: <http://dx.doi.org/10.1109/TSE.2010.81>
- <span id="page-9-1"></span>[9] "CWE List Version 3.1," ["https://cwe.mitre.org/data/index.html",]("https://cwe.mitre.org/data/index.html") 2018年。
- <span id="page-9-2"></span>[10] Z. Li, D. Zou, S. Xu, X. Ou, H. Jin, S. Wang, Z. Deng, and Y. Zhong, "Vuldeepecker: A deep learning-based system for vulnerability detection," in _25th Annual Network and Distributed System Security Symposium (NDSS 2018)_, 2018.
- <span id="page-9-4"></span>[11] R. Russell, L. Kim, L. Hamilton, T. Lazovich, J. Harer, O. Ozdemir, P. Ellingwood, and M. Mc-Conley, "Automated vulnerability detection in source code using deep representation learning," in _2018 17th IEEE International Conference on Machine Learning and Applications (ICMLA)_. IEEE, 2018, pp. 757–762.
- <span id="page-9-3"></span>[12] H. K. Dam, T. Tran, T. Pham, S. W. Ng, J. Grundy, and A. Ghose, "Automatic feature learning for vulnerability prediction," _arXiv preprint arXiv:1708.02368_, 2017.
- <span id="page-9-5"></span>[13] Juliet test suite. [オンライン]. 入手先:<https://samate.nist.gov/SRD/around.php>
- <span id="page-9-6"></span>[14] F. Yamaguchi、N. Golde、D. Arp、およびK. Rieckによる「Modeling and discovering vulnerabilities with code property graphs」は、_Proceedings of the 2014 IEEE Symposium on Security and Privacy_、SP '14に収録されています。ワシントンD.C.（アメリカ合衆国）：IEEE Computer Society、2014年、pp. 590–604。［オンライン］入手先：<http://dx.doi.org/10.1109/SP.2014.44>
- <span id="page-9-7"></span>[15] Y. Li, D. Tarlow, M. Brockschmidt, and R. Zemel, "Gated graph sequence neural networks," _arXiv preprint arXiv:1511.05493_, 2015.
- <span id="page-9-9"></span>[16] M. Schlichtkrull, T. N. Kipf, P. Bloem, R. Van Den Berg, I. Titov, and M. Welling, "Modeling relational data with graph convolutional networks," in _European Semantic Web Conference_. Springer, 2018, pp. 593–607.
- <span id="page-9-10"></span>[17] P. Velickovi ˇ c, G. Cucurull, A. Casanova, A. Romero, P. Lio, and Y. Bengio, ´ "Graph attention networks," _arXiv preprint arXiv:1710.10903_, 2017.
- <span id="page-9-11"></span>[18] "Representation Learning on Networks," ["http://snap.stanford.edu/proj/embeddings-www/",]("http://snap.stanford.edu/proj/embeddings-www/") 2018年。
- <span id="page-9-12"></span>[19] H. Dai, B. Dai, and L. Song, "Discriminative embeddings of latent variable models for structured data," in _International conference on machine learning_, 2016, pp. 2702–2711.
- <span id="page-9-13"></span>[20] Z. Ying, J. You, C. Morris, X. Ren, W. Hamilton, and J. Leskovec, "Hierarchical graph representation learning with differentiable pooling," in _Advances in Neural Information Processing Systems_, 2018, pp. 4805–4815.
- <span id="page-9-14"></span>[21] M. Zhang, Z. Cui, M. Neumann, and Y. Chen, 「グラフ分類のためのエンドツーエンド深層学習アーキテクチャ」, _Thirty-Second AAAI Conference on Artificial Intelligence_, 2018年.
- <span id="page-9-15"></span>[22] X. Du、B. Chen、Y. Li、J. Guo、Y. Zhou、Y. Liu、Y. Jiangによる "Leopard: Identifying vulnerable code for vulnerability assessment through program metrics," _arXiv preprint arXiv:1901.11479_, 2019.
- <span id="page-9-16"></span>[23] Y. Zhou と A. Sharmaによる "Automated identification of security issues from commit messages and bug reports," _Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering_, ser. ESEC/FSE 2017. New York, NY, USA: ACM, 2017, pp. 914–919. [Online]. Available:<http://doi.acm.org/10.1145/3106237.3117771>
- <span id="page-9-17"></span>[24] M. Allamanis, M. Brockschmidt, and M. Khademi, "Learning to represent programs with graphs," 2017年11月.
- <span id="page-10-0"></span>[25] J. Snoek、H. Larochelle、R. P. Adams による「機械学習アルゴリズムの実用的なベイズ最適化」という論文が、_Advances in neural information processing systems_、2012 年、 2951–2959 ページに掲載されています。
- <span id="page-10-1"></span>[26] Z. Yang, D. Yang, C. Dyer, X. He, A. Smola, and E. Hovy, "Hierarchical attention networks for document classification," in _Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies_, 2016, pp. 1480–1489.
- <span id="page-10-2"></span>[27] L. Mou、G. Li、L. Zhang、T. Wang、Z. Jinによる "Convolutional neural networks over tree structures for programming language processing." _AAAI_、vol. 2、no. 3、2016年、p. 4。
- <span id="page-10-3"></span>[28] X. Xu, C. Liu, Q. Feng, H. Yin, L. Song, and D. Song, "Neural network-based graph embedding for cross-platform binary code similarity detection," in _Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security_. ACM, 2017, pp. 363–376.

（※訳対象となる散文はありません。この行には翻訳すべき自然言語のプローズが含まれていません。）
