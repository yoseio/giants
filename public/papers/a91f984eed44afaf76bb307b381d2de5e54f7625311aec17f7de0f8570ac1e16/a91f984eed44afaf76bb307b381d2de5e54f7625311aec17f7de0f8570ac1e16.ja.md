# LEARNING TO REPRESENT PROGRAMS WITH GRAPHS

Miltiadis Allamanis Microsoft Research Cambridge, イギリス miallama@microsoft.com Marc Brockschmidt Microsoft Research Cambridge, イギリス mabrocks@microsoft.com

Mahmoud Khademi<sup>∗</sup>

サイモンフレーザー大学 バーナビー、ブリティッシュコロンビア州、カナダ mkhademi@sfu.ca

### ABSTRACT

ソースコード（つまり、形式言語）に関する学習タスクは最近注目されているが、これまでの多くの研究は自然言語の手法を転用し、コードが持つ既知のセマンティクスによる独自の可能性を十分に活かせていない。例えば、同じ変数や関数が離れた場所で使われることによって生じる長距離依存性は、しばしば考慮されていない。我々は、コードの構文的および意味的構造の両方を表現するためにグラフを用い、プログラム構造の上で推論を学習するためにグラフベースの深層学習手法を活用することを提案する。

この研究では、ソースコードからグラフを構築する方法と、Gated Graph Neural Networksのトレーニングをこのような大規模グラフにスケールさせる方法を紹介します。私たちは本手法を2つのタスクで評価しました。1つ目はVARNAMINGで、ネットワークが変数の使用箇所から名前を予測しようとします。2つ目はVARMISUSEで、ネットワークが指定されたプログラム位置で使うべき正しい変数を選ぶよう推論するタスクです。構造化されていないプログラム表現を利用した従来手法との比較により、既知の構造をモデル化する利点が示され、私たちのモデルが意味のある名前を推論したり、多くの場合でVARMISUSEタスクを解決できることが示唆されます。さらに、テストの結果、VARMISUSEは成熟したオープンソースプロジェクト内の複数のバグを特定できることがわかりました。

### 1 INTRODUCTION

大規模なソースコードリポジトリとスケーラブルな機械学習手法の登場は、「ビッグコード」というアイデア、すなわち既存のソースコードから一般化することでソフトウェアエンジニアを支援する主に自己教師ありの手法へと自然に発展しています [\(Allamanis et al., 2017\)](#page-8-0)。現在のソースコード向けのディープラーニングモデルは、その浅いテキスト構造、例えばトークン列として [\(Hindle](#page-9-0) [et al., 2012;](#page-9-0) [Raychev et al., 2014;](#page-9-1) [Allamanis et al., 2016\)](#page-8-1) や、構文解析木として [\(Maddison & Tarlow, 2014;](#page-9-2) [Bielik et al., 2016\)](#page-9-3)、あるいは変数のフラットな依存ネットワークとして [\(Raychev et al., 2015\)](#page-9-4) 捉えています。このようなモデルでは、ソースコードの豊富で明確に定義された意味情報を活用する機会を逃しています。本研究では、これを改善するためにソースコードにおける追加の2つのシグナル、すなわちデータフローと型階層を取り入れることにします。私たちはプログラムをグラフとしてエンコードし、そのエッジが構文的な関係（例：「前/後のトークン」）だけでなく、意味的な関係（「この箇所で変数が最後に使用/書き込みされた」、「引数の対応する仮引数がstreamと呼ばれる」など）も表現することでこれを実現します。このアプローチの重要な洞察は、こうした意味情報を構造化された入力として機械学習モデルに明示的に与えることで、必要な学習データ量、モデル容量、学習手法の要件を低減し、現状の最先端技術を超える課題にも対応できるようになるということです。

私たちは、プログラムのより多くのセマンティック構造を明らかにする利点を示すために、2つのタスクを検討します。最初に、VARNAMINGタスク[\(Allamanis et al., 2014;](#page-8-2) [Raychev et al., 2015\)](#page-9-4)を考えます。このタスクでは、あるソースコードが与えられたときに「正しい」変数名をサブトークンの列として推定します。これは、変数がどのように使用されているかをある程度理解する必要があり、つまり、コードの複数行にわたる推論が必要になります。

<sup>∗</sup>Microsoft Research（英国ケンブリッジ）でのインターンシップ中に行われた研究です。

```
var clazz=classTypes["Root"].Single() as JsonCodeGenerator.ClassType;
Assert.NotNull(clazz);
var first=classTypes["RecClass"].Single() as JsonCodeGenerator.ClassType;
Assert.NotNull( clazz );
Assert.Equal("string", first.Properties["Name"].Name);
Assert.False(clazz.Properties["Name"].IsArray);
```

Figure 1: オープンソースのC#プロジェクトであるRavenDBで検出されたバグのスニペットを示しています。コードは少し簡略化されています。私たちのモデルは、ハイライト（黄色）された箇所で使われている変数が誤っていることを正しく検出します。本来は、firstがその位置に使われるべきでした。私たちはこの問題を報告し、[PR 4138.](https://github.com/ravendb/ravendb/pull/4138)で修正されました。

まず、ソースファイル内で離れた場所に存在しています。次に、私たちは変数誤使用予測タスク（VARMISUSE）を導入します。このタスクでは、ネットワークがプログラムの特定の位置でどの変数を使用すべきかを推論することを目指します。タスクを説明するために、[Figure 1](#page-1-0) では、私たちのモデルが有名なオープンソースプロジェクトで検出したバグの、少し簡略化したコードスニペットを示しています。特に、clazzという変数の代わりに、黄色でハイライトされた部分ではfirstという変数が使われるべきでした。既存の静的解析手法ではこのような問題を検出できませんが、ソフトウェアエンジニアであれば経験により容易にこの誤りを見つけることができます。

これらのタスクで高い精度を達成するためには、プログラムのセマンティクス（意味的な特徴）に関する表現を学習する必要があります。両方のタスクにおいて、変数の_意味的_な役割（例：「これはカウンターか？」「これはファイル名か？」）を学習する必要があります。さらに、VARMISUSEでは変数の使用に関するセマンティクス（例：「ここではファイル名が必要である」）も学ぶ必要があります。この「空欄を埋める要素」のタスクは、Word2VecやGLoVeなど自然言語単語の分散表現学習の手法と関連しています。しかし、私たちはデータフロー情報のような、より豊かな構造から学ぶことができます。本研究はプログラム表現の学習に向けた一歩であり、このアプローチがコード補完（「これがあなたが探している変数です」）や、より高度なバグ検出（「このオブジェクトを使う前にロックすべきです」）など、幅広いタスクでも有用になると期待しています。

要約すると、私たちの貢献は次のとおりです。(i) VARMISUSEタスクを、機械学習によるソースコードのモデリングにおける課題として定義し、プログラムの（一部の）セマンティクスを学習することを要求するものとしました（[section 3](#page-2-0)参照）。(ii) コードのグラフ構造をモデリングし、そのグラフ上でプログラム表現を学習することで、VARNAMINGおよびVARMISUSEタスクを解決するためのディープラーニングモデルを提示しました（[section 4](#page-2-1)参照）。(iii) 290万行の実際のソースコードからなる大規模データセットでモデルの評価を行い、最良のモデルがVARNAMINGタスクで32.9%、VARMISUSEタスクで85.5%の精度を達成し、より単純なベースラインを上回ることを示しました（[section 5](#page-5-0)参照）。(iv) VARMISUSEの実用的な意義を、成熟したオープンソースソフトウェアプロジェクトで実際に発見したバグのいくつかを要約することで示しました（[subsection 5.3](#page-7-0)参照）。グラフニューラルネットワークの実装（より単純なタスク向け）は<https://github.com/Microsoft/gated-graph-neural-network-samples>、またデータセットは<https://aka.ms/iclr18-prog-graphs-dataset>で公開しています。

# 2 RELATED WORK

私たちの研究は、ソースコードのアーティファクトに機械学習を利用するという最近の分野に基づいています。例えば、コードをトークンの列としてモデル化する研究や、コードの構文木構造をモデル化する研究があります。これらの研究に共通しているのは、コードの言語モデルにおいて変数やメソッドの識別子を予測することが、最も大きな課題の一つであるという点です。

私たちの研究に最も近いのは [Allamanis et al.](#page-8-4) [\(2015\)](#page-8-4) の研究であり、彼らは変数のすべての使用例を利用して、その名前を予測するための分散表現を学習しています。しかし、彼らはデータフロー情報を利用しておらず、私たちの知る限りそれを利用したモデルは存在しません。[Raychev et al.](#page-9-4) [\(2015\)](#page-9-4) や [Bichsel et al.](#page-9-8) [\(2016\)](#page-9-8) は条件付き確率場を用いて、変数、AST要素、型の間のさまざまな関係をモデル化し、変数名や型の予測（あるいはAndroidアプリの難読化解除）を行っていますが、データの流れ自体は明示的に考慮されていません。これらの研究では、すべての変数の使用は事前に決定的に知られています（コードは完成していて変更されないため）、[Allamanis et al.](#page-8-2) [\(2014;](#page-8-2) [2015\)](#page-8-4) の場合も同様です。

我々の研究は、スケッチを用いたプログラム合成 [\(Solar-Lezama, 2008\)](#page-9-9) や自動コード移植 [\(Barr et al., 2015\)](#page-8-5) に関する研究と遠い関係にあります。しかし、これらの手法はギャップを埋めるために仕様（例えば、入出力例やテストスイート）を必要とし、巨大なコードから学習された統計情報を用いるわけではありません。これらの手法は我々の手法を補完するものと考えることができます。なぜなら、我々は仕様を必要とせずに、コードから一般的な変数利用パターンを学習することで統計的にギャップを補完することができるからです。

グラフに対するニューラルネットワークは、さまざまな深層学習手法をグラフ構造の入力に適応させたものです。これらはリンク予測や分類、NLPにおけるセマンティックロールラベリングなど、多様な応用で利用されています。ソースコードに多少関連するものとしては、定理証明における前提選択のために、数式のグラフベースの表現を学習する研究があります。

## <span id="page-2-0"></span>3 THE VARMISUSE TASK

コード内の変数の誤用を検出するには、プログラムの意味を理解し推論する能力が求められます。このタスクをうまく遂行するためには、プログラム要素の役割と機能を推測し、それらがどのように関連しているかを理解する必要があります。例えば、Fig. [1,](#page-1-0) のようなプログラムが与えられた場合、マークされた clazz の使用が誤りであり、代わりに first を使用すべきであることを自動的に検出するのがこのタスクです。このタスクは標準的なコード補完によく似ていますが、変数識別子のみに着目し、ほとんど完成したプログラムを対象とする点で、その範囲や目的が大きく異なります。

タスクの説明  
ソースコードファイルをトークン t<sup>0</sup> . . . t<sup>N</sup> = T の列として見なします。この中で、いくつかのトークン tλ<sup>0</sup> , tλ<sup>1</sup> . . . は変数です。さらに、V<sup>t</sup> ⊂ V を、t の位置でスコープ内にあり型が正しいすべての変数の集合とします。つまり、t で使用してもコンパイラエラーにならない変数です。正しい変数の使用を予測したいトークン tok<sup>λ</sup> を _スロット_ と呼びます。各スロット tλ について個別のタスクを定義します。すなわち、t<sup>0</sup> . . . tλ−<sup>1</sup> および tλ+1, . . . , t<sup>N</sup> が与えられたときに、Vt<sup>λ</sup> から t<sup>λ</sup> を正しく選択します。学習および評価の目的では、正しい解答とは単にグラウンドトゥルースと一致するものを指しますが、実際には複数の変数がメモリ上で同じ値を参照している場合には、いくつかの割り当てが正解と見なされることに注意してください。

## <span id="page-2-1"></span>4 MODEL: PROGRAMS AS GRAPHS

このセクションでは、プログラムのソースコードを_program graphs_に変換し、それらの上で表現を学習する方法について説明します。これらのプログラムグラフは、プログラムのテキストだけでなく、標準的なコンパイラツールを使用して得られる意味的な情報もエンコードします。

Gated Graph Neural Networks  
私たちの研究は Gated Graph Neural Networks [\(Li et al.,](#page-9-11) [2015\)](#page-9-11)（GGNN）に基づいており、ここでその概要を説明します。グラフ G = (V, E, X) は、ノードの集合 V、ノード特徴量 X、および有向エッジセットのリスト E = (E1, . . . , EK) で構成されています。ここで K はエッジタイプの数です。各 v ∈ V にはノードの特徴を表す実数値ベクトル x (v) ∈ R <sup>D</sup> が付与されています（例：そのノードの文字列ラベルの埋め込みなど）。

私たちは、各ノード v に状態ベクトル h(v) を関連付けます。これはノードラベル x(v) から初期化されます。状態ベクトルと特徴ベクトルのサイズは通常同じですが、ノード特徴量にパディングを施すことでより大きな状態ベクトルを利用することもできます。グラフ全体に情報を伝播させるため、タイプ k の「メッセージ」が各ノード v からその近傍ノードへ送信されます。各メッセージは現在の状態ベクトルから m(v)<sup>k</sup> = f<sup>k</sup>(h(v)) のように計算されます。ここで f<sup>k</sup> は任意の関数であり、私たちの場合は線形層を選択しています。グラフ上のすべてのエッジに対して同時にメッセージを計算することで、すべての状態を一度に更新することが可能です。特に、ノード v の新しい状態は、すべての受信メッセージを集約することで算出されます。すなわち、m˜(v) = g({m(u)<sup>k</sup> | タイプ k のエッジが u から v へ存在する場合}) となります。g は集約関数であり、要素ごとの加算として実装しています。集約されたメッセージ m˜(v) とノード v の現在の状態ベクトル h(v) が与えられた場合、次のタイムステップの状態 h<sup>0</sup>(v) は h<sup>0</sup>(v) = GRU(m˜(v), h(v)) のように計算されます。ここで GRU は gated recurrent unit (GRU) の再帰セル関数です。

<span id="page-3-1"></span>![](_page_3_Figure_1.jpeg)

![](_page_3_Figure_2.jpeg)

(a) 図[1,](#page-1-0) の2行目に対する簡略化した構文グラフであり、青色の丸みを帯びたボックスは構文ノード、黒い長方形のボックスは構文トークン、青いエッジはChildエッジ、そして黒の二重線エッジはNextTokenエッジを示しています。

(b) データフローエッジとして、(x <sup>1</sup>,y <sup>2</sup>) = Foo(); while (x <sup>3</sup> > 0) x <sup>4</sup> = x <sup>5</sup> + y <sup>6</sup>（明確化のために添え字を追加）、赤の点線はLastUseエッジ、緑の破線はLastWriteエッジ、紫の一点鎖線はComputedFromエッジを表している。

Figure 2: プログラム表現で使用されるグラフエッジの例。

上記の方程式によって定義されるダイナミクスを、あらかじめ決められたタイムステップ数だけ繰り返します。その後、最後のタイムステップにおける状態ベクトルをノード表現として使用します。[1](#page-3-0)

Program Graphs  
プログラムのソースコードをグラフとして表現し、異なるエッジタイプを使ってさまざまなトークン間の構文的および意味的な関係をモデル化します。プログラムグラフの基盤は、プログラムの抽象構文木（AST）であり、これは_構文ノード_（プログラミング言語の文法における非終端記号に対応）と_構文トークン_（終端記号に対応）から構成されます。構文ノードにはプログラムの文法における非終端記号の名前をラベル付けし、構文トークンにはそれが表す文字列をラベル付けします。Childエッジを使用して、ASTに従ってノード同士を接続します。ただし、これだけでは構文ノードの子ノード間に順序が生じないため、追加でNextTokenエッジを用いて各構文トークンをその後続トークンと接続します。この例をFig. [2a.](#page-3-1) に示します。

プログラム内の制御とデータの流れを把握するために、変数に対応する構文トークンのさまざまな使用箇所や更新箇所を接続する追加のエッジを加えます。このようなトークン v に対して、DR(v) を変数が最後に使用された可能性のある構文トークンの集合とします。この集合には複数のノード（例えば、条件分岐の両方の分岐で変数が使用された後など）が含まれることがあり、さらにプログラムコードの後続の構文トークン（ループの場合など）も含まれることがあります。同様に、D<sup>W</sup>(v) をその変数が最後に書き込まれた構文トークンの集合とします。これらを用いて、v から DR(v)（それぞれ D<sup>W</sup>(v)）のすべての要素に LastRead（それぞれ LastWrite）エッジを追加します。さらに、代入 v = expr を観測した場合には、expr 内に登場するすべての変数トークンから v まで ComputedFrom エッジで接続します。このようなセマンティックエッジの例は Fig. [2b.](#page-3-1) に示されています。

同じ変数が使われている箇所すべてを連鎖させるために、LastLexicalUseエッジを使ってグラフを拡張します（データフローとは独立しており、例えば if (...) { ... v ...} else { ... v ...} のような場合、vが出現する両方をリンクします）。また、returnトークンをメソッド宣言にReturnsToエッジで接続します（これにより、その名前や型への「ショートカット」が作られます）。[Rice et al.](#page-9-19) [\(2017\)](#page-9-19) に着想を得て、メソッド呼び出しの引数を対応する仮引数へFormalArgNameエッジで接続します。つまり、呼び出しFoo(bar)とメソッド宣言Foo(InputStream stream)を観察した場合、barトークンからstreamトークンへエッジを張ります。最後に、変数に対応するすべてのトークンを、その変数が使われているガード式とGuardedByおよびGuarded-ByNegationエッジで接続します。例えば、if (x > y) { ... x ...} else { ... y ...} の場合、xから（yの場合はGuardedByNegationエッジで）x > yに対応するASTノードへエッジを追加します。

最後に、すべての種類のエッジについて、それぞれに対応する逆向きのエッジ（隣接行列の転置）を導入します。これにより、エッジとエッジタイプの数が2倍になります。逆向きのエッジは、GGNN内で情報をより速く伝播させるのに役立ち、モデルの表現力を高めます。

<sup>1</sup>Graph Convolutional Networks (GCN) [\(Kipf & Welling, 2016;](#page-9-13) [Schlichtkrull et al., 2017\)](#page-9-20) は、GGNNのより単純な代替手段となります。これは、状態更新においてゲート付きリカレントユニットを使用せず、GGNNレイヤーごとの伝播ステップ数を1に固定した、GGNNの特殊なケースに相当します。その代わり、複数のレイヤーが利用されます。我々の実験では、GCNはGGNNほど汎化性能が高くありませんでした。

変数型情報の活用  
私たちは、静的型付け言語を前提とし、ソースコードがコンパイル可能であるため、各変数には（既知の）型 τ (v) が割り当てられていると想定します。これを利用するために、既知の型には学習可能な埋め込み関数 r(τ ) を定義し、さらに未知または未表現の型すべてに対して "UNKTYPE" を定義します。また、多くのオブジェクト指向言語で利用可能な豊富な型階層も活用します。このために、変数の型 τ (v) を、そのスーパータイプの集合、すなわち τ ∗ (v) = {τ : τ (v) implements type τ} ∪ {τ (v)} へとマッピングします。次に、変数 v の型表現 r ∗ (v) を {r(τ ) : τ ∈ τ ∗ (v)} の要素ごとの最大値として計算します。ここで最大値を選ぶのは、型格子のような部分順序関係を表現する際の自然なプーリング手法だからです。τ ∗ (v) に含まれるすべての型を利用することで、共通のスーパータイプやインターフェースを実装する未知の型に対しても一般化することができます。たとえば、List<K> は複数の具体的な型（List<int>、List<string> など）を持ちますが、これらの型は共通のインターフェース（IList）を実装し、共通の特性を共有しています。学習中には τ ∗ (v) の非空部分集合をランダムに選択することによって、型格子内のすべての既知の型が学習されることを保証します。これは、ドロップアウト機構のように機能するだけでなく、型格子内のすべての型に対して良い表現を学習することにもつながります。

Initial Node Representation  
初期ノード状態を計算するために、トークンのテキスト表現とその型情報を組み合わせます。具体的には、トークンを表すノードの名前をcamelCaseやpascal_caseでサブトークンに分割します（例：classTypesという名前はclassとtypesという二つのサブトークンに分けられます）。そして、全てのサブトークンの埋め込み表現の平均をとることで、ノード名の埋め込みを取得します。最後に、以前述べた型表現r ∗ (v)を学習し、それをノード名の表現と結合して線形層に通し、グラフ内の各ノードの初期表現を得ます。

Programs Graphs for VARNAMING  
与えられたプログラムと既存の変数vについて、前述のようにプログラムグラフを構築し、対応するすべての変数トークンにおける変数名を特別な<SLOT>トークンに置き換えます。名前を予測するために、先ほど述べたように学習可能なトークン埋め込みと型埋め込みを連結して初期ノードラベルを計算し、GGNNの伝播を8ステップ行います。また、すべての<SLOT>トークンの表現を平均することで変数の使用表現を算出します。この表現を1層のGRUの初期状態として使用し、ターゲットとなる名前をサブトークンの列として予測します（例えば、名前inputStreamBufferは[input, stream, buffer]という列として扱われます）。このgraph2seqアーキテクチャは最尤推定目的で学習されます。[section 5](#page-5-0) では、正確な名前予測の精度とサブトークン予測のF1スコアについて報告します。

VARMISUSE のためのプログラムグラフ  
プログラムグラフを用いて VARMISUSE をモデル化するには、グラフを修正する必要があります。まず、変数を予測したいスロット t の _コンテキスト表現_ c(t) を計算するために、t の位置に新しいノード v<SLOT> を挿入します。これは、この時点で「穴」があることに対応しており、選択された変数に依存しないすべての関連するエッジ（_すなわち_、LastUse, LastWrite, LastLexicalUse, GuardedBy エッジ以外すべて）を使って、残りのグラフと接続します。次に、ターゲットスロットにおける各候補変数 v の _使用表現_ u(t, v) を計算するために、Vt 内のすべての v に対して「候補」ノード vt,v を挿入し、その変数がこのスロットで使用される場合に利用される LastUse, LastWrite, LastLexicalUse エッジを接続します。これらの各候補ノードは、スコープ内で変数を仮に配置した場合を表現しています。

初期のノード表現に、候補ノード vt,v に対して 1 に設定された追加のビットを連結し、GGNN 伝播を 8 ステップ実行します。コンテキストおよび使用法の表現は、各ノードの最終的なノード状態となります。すなわち、c(t) = h (v<SLOT>) および u(t, v) = h (vt,v) です。最後に、その場所での正しい変数使用は、arg max<sup>v</sup> W[c(t), u(t, v)] として計算されます。ここで W は c(t) と u(t, v) の連結を使う線形層です。学習にはマージン最大化目的関数を用います。

#### 4.1 IMPLEMENTATION

大きく多様なグラフの集合に対してGGNNを使用するには、効率的なバッチ処理が多様な形状の存在下で困難なため、多少のエンジニアリング作業が必要になります。重要な点は、大きなグラフは通常非常にスパース（疎）であるため、エッジを隣接リストとして表現することで、メモリ消費を削減できるということです。今回の場合、これはスパーステンソルを用いることで容易に実装できます。

<sup>2</sup>私たちの調査によると、ステップ数が少なすぎると十分な結果が得られず、反対に伝播ステップを増やしても大きな効果は見られませんでした。

バッチ処理のために、現代のGPUの並列処理能力を効率的に活用できる大きなバッチサイズを可能にしています。もう一つの重要な着想は、複数のグラフからなるバッチを、複数の連結していない成分からなる一つの大きなグラフとして表現することです。これには、ノードの識別子を一意にするための適切な前処理が必要となります。このバッチ構築はCPUへの負荷がやや高くなるため、私たちはミニバッチの準備を別スレッドで行うのが有効であることを発見しました。私たちのTensorFlow [\(Abadi et al., 2016\)](#page-8-6) 実装では、単一のNVidia GeForce GTX Titan Xを用いて、平均2,228（中央値936）ノードおよび8,350（中央値3,274）エッジを持つグラフ、8回のGGNNアンローリング反復、20種類すべてのエッジタイプ（10種類の元のエッジタイプそれぞれに前向き・後向きエッジ）、隠れ層サイズ64という設定で、トレーニング時に1秒あたり最大55グラフ、テスト時に1秒あたり219グラフのスケーリングが可能です。GGNN内のエッジタイプの数は、実行時間に比例して影響します。例えば、アブレーションスタディのために最も一般的な2つのエッジタイプ（NextToken、Child）のみを用いたGGNNの実行では、同じハイパーパラメータでトレーニング時に1秒あたり105グラフ、テスト時には1秒あたり419グラフを処理することができます。GGNNの（汎用的な）実装は、[https://github.com/Microsoft/](https://github.com/Microsoft/gated-graph-neural-network-samples) [gated-graph-neural-network-samples](https://github.com/Microsoft/gated-graph-neural-network-samples) にて、よりシンプルなデモ用タスクを用いて公開されています。

### <span id="page-5-0"></span>5 EVALUATION

Dataset  
VARMISUSEタスクのためのデータセットを、GitHub上のオープンソースC#プロジェクトから収集しました。プロジェクトの選定には、GitHubで最もスター数の多い（フォークでない）プロジェクトを選びました。その後、Roslynを使って完全に（簡単に）コンパイルできないプロジェクトを除外しました。これは、コード内の正確な型情報（外部ライブラリに含まれる型も含む）を抽出するためにコンパイルが必要だからです。最終的なデータセットには、さまざまな分野（コンパイラ、データベースなど）から29件のプロジェクトが含まれており、約290万行の空でないコード行があります。全体の一覧表は、[Appendix D.](#page-15-0) に示されています。

変数誤用の検出タスクのために、すべてのプロジェクトからデータを収集します。具体的には、すべての変数使用箇所を選び、変数宣言を除外しつつ、そのスコープ内に少なくとも1つ以上の型互換な代替変数が存在する場所のみを抽出します。このタスクは、その位置に元々存在していた正しい変数を推論することです。そのため、設計上、少なくとも1つの型が正しい代替変数が必ず存在し、これを選んだ場合でも型チェック時にエラーは発生しません。テストデータセットでは、各スロットごとに平均して3.8個の型が正しい代替変数（中央値3、σ = 2.6）が存在しています。

私たちのデータセットから、2つのプロジェクトを開発セットとして選択しました。残りのプロジェクトからは、まったく未知の構造や型を持つプロジェクトでのテストを可能にするために、3つのプロジェクトをUNSEENPROJTEST用に選びました。さらに残った23のプロジェクトを、60-10-30の比率で訓練、検証、テストセットに分割しました。このとき、ファイル単位で分割し（すなわち、1つのソースファイルからのすべての例は同じセットに含まれるようにしました）、この方法で得られるテストセットをSEENPROJTESTと呼びます。

VARMISUSEのベースラインとして、我々は2つの双方向RNNベースのベースラインを検討する。ローカルモデル（LOC）は、ターゲット位置の前後のトークンに対して2層の双方向GRUをシンプルに適用したものである。このベースラインでは、c(t)はRNNによって計算されたスロット表現に設定され、各変数の使用コンテキストu(t, v)は、変数の名前と型の埋め込みであり、これはGGNNの初期ノードラベルと同じ方法で計算される。このベースラインにより、このタスクのための使用コンテキスト情報の重要性を評価できる。フラットデータフローモデル（AVGBIRNN）はLOCの拡張であり、使用表現u(t, v)は、各使用前後のトークンに対して別の2層双方向RNNを適用し、変数トークンvにおける計算結果を平均することで求められる。ローカルコンテキストc(t)はLOCと同じである。AVGBIRNNは、すべての変数使用にわたる平均化が長距離依存関係に役立つため、すでにいくつかの構造情報を考慮している大幅に強力なベースラインである。両モデルとも、c(t)<sup>T</sup>u(t, v)を最大化する変数を選択する。

VARNAMINGの場合、LOCをAVGLBLに置き換えます。AVGLBLは、各変数使用時の左4トークンと右4トークンを文脈として対数双線形モデルを用い、それらの文脈表現を平均化します（これは[Allamanis et al.](#page-8-4) [\(2015\)](#page-8-4)のモデルに対応します）。また、VARNAMINGにおいてAVGBIRNNもテストしており、これは基本的に対数双線形文脈モデルを双方向RNNに置き換えたものです。

|              | SEENPROJTEST |        |          |       | UNSEENPROJTEST |        |          |       |
| ------------ | ------------ | ------ | -------- | ----- | -------------- | ------ | -------- | ----- |
|              | LOC          | AVGLBL | AVGBIRNN | GGNN  | LOC            | AVGLBL | AVGBIRNN | GGNN  |
| VARMISUSE    |              |        |          |       |                |        |          |       |
| Accuracy (%) | 50.0         | —      | 73.7     | 85.5  | 28.9           | —      | 60.2     | 78.2  |
| PR AUC       | 0.788        | —      | 0.941    | 0.980 | 0.611          | —      | 0.895    | 0.958 |
| VARNAMING    |              |        |          |       |                |        |          |       |
| Accuracy (%) | —            | 36.1   | 42.9     | 53.6  | —              | 22.7   | 23.4     | 44.0  |
| F1 (%)       | —            | 44.0   | 50.1     | 65.8  | —              | 30.6   | 32.0     | 62.0  |

この表は、SEENPROJTESTおよびUNSEENPROJTESTの両データセットにおけるVARMISUSEとVARNAMINGタスクの各モデルのパフォーマンスを示しています。Accuracy（正解率）、PR AUC、F1スコアなどの評価指標を用いて、LOC、AVGLBL、AVGBIRNN、GGNNの各モデルの結果が比較されています。ダッシュ（—）は該当する値が存在しない、または評価されていないことを表します。

<span id="page-6-1"></span>表1：モデルの評価。SEENPROJTEST は、トレーニングセットにファイルが含まれているプロジェクトからなるテストセットを指し、UNSEENPROJTEST はトレーニングデータにファイルが一切含まれていないプロジェクトを指します。結果は2回の実行の平均です。

<span id="page-6-3"></span>

| Table 2: SEENPROJTEST における2つのタスクに対する GGNN モデルのアブレーションスタディ。 |     |     |     |     |
| ------------------------------------------------------------------------------- | --- | --- | --- | --- |
| ------------------------------------------------------------------------------- | --  | --  | --  | --  |

|                                                 | Accuracy (%) |           |     |     |
| ----------------------------------------------- | ------------ | --------- | --- | --- |
| Ablation Description                            | VARMISUSE    | VARNAMING |     |     |
| Standard Model (reported in Table 1)            | 標準モデル（表1に記載）            | 85.5         | 53.6      |     |     |
| Only NextToken, Child, LastUse, LastWrite edges | NextToken、Child、LastUse、LastWriteエッジのみ使用 | 80.6         | 31.2      |     |     |
| Only semantic edges (all but NextToken, Child)  | セマンティックエッジのみ（NextToken、Child以外すべて） | 78.4         | 52.9      |     |     |
| Only syntax edges (NextToken, Child)            | シンタックスエッジのみ（NextToken、Child）            | 55.3         | 34.3      |     |     |
| Node Labels: Tokens instead of subtokens        | ノードラベル：サブトークンの代わりにトークンを使用        | 85.6         | 34.5      |     |     |
| Node Labels: Disabled                           | ノードラベル：無効化                                      | 84.3         | 31.8      |     |     |

## 5.1 QUANTITATIVE EVALUATION

[Table 1](#page-6-1)は、両タスクにおけるモデルの評価結果を示しています。[4](#page-6-2) LOCはほとんど情報を捉えていないため、比較的低い性能となっています。AVGLBLとAVGBIRNNは多くの変数使用箇所から情報を取得しますが、この問題の豊かな構造を明示的にエンコードしていないため、GGNNよりも大きく劣っています。特にVARMISUSEタスクにおいては、コードの構造やセマンティクスがより重要となるため、パフォーマンスの差がさらに大きくなっています。

新しいプロジェクトへの一般化  
異なるドメインを持つ多様なソースコードプロジェクト全体で一般化することは、機械学習における重要な課題です。私たちは、トレーニングセットにファイルが一切含まれていないプロジェクトに由来するUNSEENPROJTESTセットを用いて再度評価を行いました。[Table 1](#page-6-1)の右側が示しているように、私たちのモデルはSEENPROJTESTと比較するとわずかに性能が下がりますが、それでも良好なパフォーマンスを維持しています。これは、UNSEENPROJTESTでは型ラティスの大部分が未知であるため、予想された結果です。

私たちは、訓練されたモデルを未知のプロジェクト（つまり、ドメイン）に適用する際の主な問題は、その型階層が不明であり、使用されている語彙（例えば、変数名、メソッド名、クラス名など）が大きく異なる可能性があるという点にあると考えています。

Ablation Study  
我々のモデルのいくつかの設計上の選択がもたらす効果を調べるため、追加の実験を行い、その結果を[Table 2.](#page-6-3)に示している。まず、プログラムグラフで使用するエッジを変更した。モデルを構文情報のみに制限すると、両タスクでパフォーマンスに大きな影響があることがわかった。一方、意味的なエッジのみに制限すると、主にVARMISUSEでパフォーマンスに影響するようである。同様に、ComputedFrom、FormalArgName、ReturnsToの各エッジはVARMISUSEではわずかな効果だが、VARNAMINGではパフォーマンスを大きく向上させることがわかった。ノードラベル表現を使った実験からも分かるように、構文ノードやトークン名はVARMISUSEにはほとんど影響しないが、VARNAMINGには大きな影響を与えることが自然な結果である。

# 5.2 QUALITATIVE EVALUATION

[Figure 3](#page-7-1) は、GGNN がサンプルのテストスニペットに対して行った予測を示しています。スニペットは、グローバルなディレクティブファイルをルートフォルダまで徐々に降りながら再帰的に探索します。正しい変数の使用方法について推論するのは、人間にとっても難しいですが、GGNN は正しく変数を予測しています。

<span id="page-6-0"></span><sup>3</sup><http://roslyn.io>

<span id="page-6-2"></span><sup>4</sup> セクション [A](#page-10-0) では、VARMISUSEタスクにおけるGGNNモデルのROC曲線と適合率-再現率曲線も示しています。

<span id="page-7-1"></span>![](_page_7_Figure_1.jpeg)

Figure 3: ServiceStackプロジェクトのSEENPROJTESTセットのスニペット内スロットに対するVARMISUSEの予測結果を示しています。追加の可視化は[Appendix B.](#page-10-1)で見ることができます。下線が引かれたトークンは正しいトークンです。モデルは、各スロットで複数の文字列変数から選択しなければなりませんが、それらはすべて何らかのパスを表しています。GGNNは、変数同士が複雑に関係し合う方法を推論し、13個のスロットのうち11個で正しい変数の使用を正確に予測しました。

```
public ArraySegment<byte> ReadBytes(int length){
   int size = Math.Min(length, _len - _pos);
   var buffer = EnsureTempBuffer( length );
   var used = Read(buffer, 0, size);
```

Figure 4: RavenDB オープンソースプロジェクトで発見されたバグ（黄色）。このコードでは、バッファのサイズを size ではなく length にしているが、これは不要な処理であり、この箇所では私たちのモデルが正しい変数として size を予測している。

2つ（スロット1と8）を除くすべての場所での使用例です。ソフトウェアエンジニアがコードを書いているとき、ある変数の代わりに別の変数を間違って使ってしまうことが考えられます。すべての変数が文字列変数であるため、型エラーは発生しません。Fig. [3](#page-7-1) の確率が示すように、多くの潜在的な変数の誤使用はモデルによって指摘され、ソフトウェアエンジニアにとって有用な警告となります。コメント付きの追加サンプルは [Appendix B.](#page-10-1) にあります。

さらに、[Appendix C](#page-14-0) では、GGNNの使用表現 u(t, v) のコサイン類似度によって計算された、類似した表現を持つコードスニペットのペアのサンプルを示しています。読者は、ネットワークが意味的に類似した変数の使用をグループ化することを学習していることに気づくでしょう。例えば、変数を使用する前にnullチェックを行う場合、コードの複数のセグメントで類似した分散表現が得られます（[Appendix C](#page-14-0) のサンプル1）。

#### <span id="page-7-0"></span>5.3 DISCOVERED VARIABLE MISUSE BUGS

私たちは、RavenDB（ドキュメントデータベース）とRoslyn（MicrosoftのC#コンパイラフレームワーク）におけるバグが発生しやすい箇所を特定するために、VARMISUSEモデルを使用しました。このために、両プロジェクトにおいてモデルが最も自信を持って実際の値とは異なる変数を選んだ上位500箇所のサンプルを手動で確認し、それぞれのプロジェクトで3件ずつバグを発見しました。

Figs. [1,](#page-1-0)[4](#page-7-2)[,5](#page-8-7) は、RavenDBで発見された問題を示しています。Fig. [1](#page-1-0) のバグは、コピー＆ペーストが原因である可能性があり、従来の手法では簡単に見つけることができません。コンパイラは、次のような場合に警告を _出しません_

```
if (IsValidBackup(backupFilename) == false) {
 output("Error:"+ backupLocation +" doesn't look like a valid backup");
 throw new InvalidOperationException(
     backupLocation + " doesn't look like a valid backup");
```

Figure 5: RavenDBオープンソースプロジェクトで発見されたバグ（黄色）。backupFilenameがIsValidBackupによって無効であると判定されているにもかかわらず、ユーザーにはbackupLocationが無効であると通知されている。

未使用の変数（firstは使用されているため該当しません）や、ほとんど誰も別のテストをテストするようなテストを書くことはありません。図[4](#page-7-2)は、重大ではないもののメモリ消費量が増加する可能性のある問題を示しています。図[5](#page-8-7)は、情報量に乏しいエラーメッセージが原因で発生する別の問題を示しています。私たちは、さらに3件のバグを[Roslyn](http://roslyn.io)の開発者に非公開で報告し、それらの問題はすでに修正されています（cf. <https://github.com/dotnet/roslyn/pull/23437>）。報告したバグの一つは、特定のRoslyn機能を使用した際にVisual Studioがクラッシュする可能性があるものでした。

広くリリースされ、テストされたコードでこれらの問題が見つかったことは、私たちのモデルがクラシックなプログラム解析ツールを補完し、ソフトウェア開発プロセスの中で有用である可能性を示しています。例えば、1つの利用シナリオとしては、VARMISUSEモデルが異常と特定した箇所へコードレビューのプロセスを誘導したり、テストや高コストなコード解析作業を重点的に行う場所を選ぶ手がかりとして利用したりすることが考えられます。

### 6 DISCUSSION & CONCLUSIONS

ソースコードはプログラミング言語研究など他の分野では十分に理解され、研究されていますが、ディープラーニングにとっては比較的新しい領域です。テキストや知覚データとは異なり、その（局所的な）意味が明確に定義されており、よく知られた効率的なプログラム解析を用いて豊富な追加情報を抽出できるという新たな可能性を持っています。一方で、この豊富な構造化情報を統合することは興味深い課題となります。私たちのVARMISUSEタスクは、コード補完のようなより単純なタスクを超えて、これらの可能性を示しています。このタスクはソースコードの「意味」を学習するという中核的課題への最初の指標と考えており、型システムに通常含まれる情報を確率的に洗練する必要がある点で重要です。

### REFERENCES

- <span id="page-8-6"></span>Martín Abadi、Ashish Agarwal、Paul Barham、Eugene Brevdo、Zhifeng Chen、Craig Citro、Greg S Corrado、Andy Davis、Jeffrey Dean、Matthieu Devin ほか。Tensorflow: 大規模な機械学習を異種分散システム上で実現するためのプラットフォーム。_arXiv preprint arXiv:1603.04467_, 2016年。
- <span id="page-8-2"></span>Miltiadis Allamanis、Earl T Barr、Christian Bird、および Charles Sutton。「Learning natural coding conventions」。_Foundations of Software Engineering (FSE)_、2014年。
- <span id="page-8-4"></span>Miltiadis Allamanis、Earl T Barr、Christian Bird、そしてCharles Suttonによる論文。「正確なメソッド名およびクラス名の提案」について述べられています。これは2015年の _Foundations of Software Engineering (FSE)_ に掲載されました。
- <span id="page-8-1"></span>Miltiadis Allamanis、Hao Peng、Charles Suttonによる論文「A convolutional attention network for extreme summarization of source code」は、_International Conference on Machine Learning (ICML)_ にて、2016年に2091–2100ページに掲載された。
- <span id="page-8-0"></span>Miltiadis Allamanis、Earl T Barr、Premkumar Devanbu、Charles Suttonによる論文「A survey of machine learning for big code and naturalness」。_arXiv preprint arXiv:1709.06182_, 2017年。
- <span id="page-8-5"></span>Earl T Barr, Mark Harman, Yue Jia, Alexandru Marginean, および Justyna Petke。自動化されたソフトウェア移植について。_International Symposium on Software Testing and Analysis (ISSTA)_、2015年。
- <span id="page-8-8"></span>Al Bessey、Ken Block、Ben Chelf、Andy Chou、Bryan Fulton、Seth Hallem、Charles Henri-Gros、Asya Kamsky、Scott McPeak、Dawson Engler。数十億行におよぶコードを経て：実世界でバグを発見するための静的解析の利用について。 _Communications of the ACM_, 53(2):66–75, 2010年。
- <span id="page-8-3"></span>Avishkar Bhoopchand、Tim Rocktäschel、Earl Barr、Sebastian Riedel。疎なポインタネットワークを用いたPythonコード提案の学習。_arXiv preprint arXiv:1611.08307_, 2016年。
- <span id="page-9-8"></span>Benjamin Bichsel、Veselin Raychev、Petar Tsankov、Martin Vechevによる「Statistical deobfuscation of android applications」。_Conference on Computer and Communications Security (CCS)_、2016年に発表された論文です。
- <span id="page-9-3"></span>Pavol Bielik、Veselin Raychev、Martin VechevによるPHOG: コードのための確率モデル。_International Conference on Machine Learning (ICML)_, 2016年。
- <span id="page-9-18"></span>Kyunghyun Cho、Bart van Merriënboer、Dzmitry Bahdanau、Yoshua Bengioによる論文です。ニューラル機械翻訳の特性について、エンコーダ–デコーダ手法を扱っています。_Syntax, Semantics and Structure in Statistical Translation_, 2014年。
- <span id="page-9-12"></span>Michaël Defferrard、Xavier Bresson、Pierre Vandergheynst。グラフ上での高速な局所スペクトルフィルタリングによる畳み込みニューラルネットワーク。_Neural Information Processing Systems (NIPS)_、pp. 3844–3852、2016年。
- <span id="page-9-14"></span>Justin Gilmer、Samuel S. Schoenholz、Patrick F. Riley、Oriol Vinyals、George E. Dahlによる論文です。量子化学のためのニューラルメッセージパッシングについて述べられています。_arXiv preprint arXiv:1704.01212_, 2017年。
- <span id="page-9-10"></span>Marco Gori、Gabriele Monfardini、および Franco Scarselli による論文です。グラフ領域での学習のための新しいモデルについて述べています。_IEEE International Joint Conference Neural Networks (IJCNN)_ にて発表されました。IEEE、2005年。
- <span id="page-9-15"></span>Aditya Grover と Jure Leskovec による node2vec: ネットワークのためのスケーラブルな特徴学習に関する論文です。_International Conference on Knowledge Discovery and Data Mining (SIGKDD)_ にて、pp. 855–864、ACM、2016年に発表されました。
- <span id="page-9-0"></span>Abram Hindle、Earl T Barr、Zhendong Su、Mark Gabel、および Premkumar Devanbu。ソフトウェアの自然さについて。_International Conference on Software Engineering (ICSE)_、2012年。
- <span id="page-9-13"></span>Thomas N Kipf と Max Welling. グラフ畳み込みネットワークを用いた半教師あり分類。 _arXiv preprint arXiv:1609.02907_, 2016年.
- <span id="page-9-11"></span>Yujia Li、Daniel Tarlow、Marc Brockschmidt、Richard Zemelによる “Gated graph sequence neural networks”。これは _International Conference on Learning Representations (ICLR)_、2015年で発表されたものです。
- <span id="page-9-2"></span>Chris J MaddisonとDaniel Tarlowによる「Structured generative models of natural source code」。_International Conference on Machine Learning (ICML)_、2014年。
- <span id="page-9-16"></span>Diego Marcheggiani と Ivan Titov による論文。「文をグラフ畳み込みネットワークでエンコードすることによる意味役割付与」。_ACL_ 2017 年発表。
- <span id="page-9-5"></span>Tomas Mikolov、Ilya Sutskever、Kai Chen、Greg S Corrado、Jeff Deanによる論文。単語やフレーズの分散表現とそれらの合成性について論じています。_Neural Information Processing Systems (NIPS)_、2013年に発表されました。
- <span id="page-9-6"></span>Jeffrey Pennington、Richard Socher、およびChristopher D Manningによる論文「GloVe: Global vectors for word representation」は、2014年の_EMNLP_で発表されました。
- <span id="page-9-1"></span>Veselin Raychev、Martin Vechev、およびEran Yahavによる論文。「Code completion with statistical language models」。_Programming Languages Design and Implementation (PLDI)_ にて、2014年、pp. 419–428。
- <span id="page-9-4"></span>Veselin Raychev、Martin Vechev、Andreas Krause。Big Codeからプログラムの特性を予測する。_Principles of Programming Languages (POPL)_、2015年。
- <span id="page-9-7"></span>Veselin Raychev、Pavol Bielik、Martin Vechevによる「Probabilistic model for code with decision trees」。_Object-Oriented Programming, Systems, Languages, and Applications (OOPSLA)_、2016年。
- <span id="page-9-19"></span>Andrew Rice、Edward Aftandilian、Ciera Jaspan、Emily Johnston、Michael Pradel、Yulissa Arroyo-Paredesによる論文「Detecting argument selection defects」は、_Proceedings of the ACM on Programming Languages_ の 1(OOPSLA):104, 2017 に掲載されています。
- <span id="page-9-20"></span>Michael Schlichtkrull、Thomas N. Kipf、Peter Bloem、Rianne van den Berg、Ivan Titov、Max Welling 著。グラフ畳み込みネットワークによる関係データのモデリング。 _arXiv preprint arXiv:1703.06103_, 2017年。
- <span id="page-9-9"></span>Armando Solar-Lezama. _Program synthesis by sketching_. University of California, Berkeley, 2008.
- <span id="page-9-17"></span>Mingzhe Wang、Yihe Tang、Jian Wang、Jia Dengによる論文「Premise selection for theorem proving by deep graph embedding」は、2017年の_Advances in Neural Information Processing Systems_において、2783–2793ページに掲載されています。

<span id="page-10-2"></span>![](_page_10_Figure_1.jpeg)

Figure 6: VARMISUSEにおけるGGNNモデルのPrecision-RecallカーブおよびROCカーブ。なお、y軸は50%から始まっている点に注意してください。

Table 3: VARMISUSEにおける、型が正しくスコープ内にある候補変数の数ごとのGGNNモデルの性能。ここでは、サブトークンを使用した完全なGGNNモデルの性能を計算している。

| # of candidates                | 2    | 3    | 4    | 5    | 6 or 7 | 8+   |
| ------------------------------ | ---- | ---- | ---- | ---- | ------ | ---- |
| Accuracy on SEENPROJTEST (%)   | 91.6 | 84.5 | 81.8 | 78.6 | 75.1   | 77.5 |
| Accuracy on UNSEENPROJTEST (%) | 85.7 | 77.1 | 75.7 | 69.0 | 71.5   | 62.4 |

### <span id="page-10-0"></span>A PERFORMANCE CURVES

[Figure 6](#page-10-2) は、GGNNモデルのROC曲線と適合率-再現率曲線を示しています。ご覧のとおり、偽陽性率を10%に設定した場合、SEENPROJTESTでは真陽性率[5](#page-10-3)が73%、未知のテストでは69%となっています。これは、このモデルが高い適合率設定でも実用的に十分な性能を発揮できる可能性を示唆しています。

## <span id="page-10-1"></span>B VARMISUSE PREDICTION SAMPLES

以下に、SEENPROJTESTプロジェクトからのサンプルと、モデルの性能に関するコメントを示します。コードのコメントやフォーマットは、組版上の理由により変更されている場合があります。正解の選択肢は下線で示されています。

### Sample 1

![](_page_10_Figure_10.jpeg)

| #1   | 開始地点: 97%から   |     | 終了地点: 3%まで   |     |
| ---- | -------------------- | --- | -------------- | --- |
| ---- | -------------------- | --  | -------------- | --  |

#2 ポート：100%、開始時：0%、終了時：0%

#3 endingAt: 100%、startingFrom: 0%、port: 0%

#4ポート：100%、開始時：0%、終了時：0%

- #5 ポート: 100%、開始時: 0%、終了時: 0%
- #6 port: 100%、開始時点: 0%、終了時点: 0%

モデルはループ内のすべての変数を正確に予測しています。

<span id="page-10-3"></span><sup>5</sup>業界では10%の誤検知率が広く受け入れられており、最大許容限度は30%とされています[\(Bessey](#page-8-8) [et al., 2010\)](#page-8-8)。

サンプル2

![](_page_11_Figure_2.jpeg)

#3 パス: 76%、名前: 16%、DIR_PATH: 8%

. 文字列変数は混同されることなく、その意味的な役割が正しく推測されます。

サンプル3

```
[global::System.Diagnostics.DebuggerNonUserCodeAttribute]
public void MergeFrom(pb::CodedInputStream input) {
 uint tag;
 while ((tag = input.ReadTag()) != 0) {
   switch(tag) {
    default:
      input.SkipLastField();
      break;
    case 10: {
       #1 .AddEntriesFrom(input, _repeated_payload_codec);
      break;
    }
   }
 }
}
```

#1 ペイロード：66%、payload\_：44%

. このモデルは、しばしばエイリアス、つまりメモリ上の同じ場所を指している変数によって混乱することがあります。この例では、どちらの選択肢でも同じ動作になったでしょう。

Sample 4

![](_page_11_Figure_10.jpeg)

#1 \_gate: 99%、\_observers: 1% #2 \_isDisposed: 90%、\_isStopped: 8%、HasObservers: 2%

ReturnsToエッジは、そうでなければ予測が不可能だった変数を予測するのに役立つ可能性があります。

#### Sample 5

| /// <summary><br/>/// 発生した例外について、すべての購読中のオブザーバに通知します。<br/>/// </summary>                         |
| ----------------------------------------------------------------------------------------------------------------------- |
| /// <param name="error"/> すべてのオブザーバに送信する例外。<br>public override void OnError(Exception error)<br>{ |
| if (<br>#1<br>== null)<br>throw new ArgumentNullException(nameof(<br>#2<br>));                                          |
|                                                                                                                         |
| var os = default(IObserver <t>[]);</t>                                                                                  |
| lock (<br>#3<br>)                                                                                                       |
| {<br>CheckDisposed();                                                                                                   |
| if (!<br>#4<br>)<br>{                                                                                                   |
| os = \_observers.Data;<br>\_observers = ImmutableList <iobserver<t>&gt;.Empty;</iobserver<t>                            |
| #5<br>= true;                                                                                                           |
| #6<br>=<br>#7<br>;                                                                                                      |
| }<br>}                                                                                                                  |
| if (os != null)                                                                                                         |
| {<br>foreach (var o in os)                                                                                              |
| {                                                                                                                       |
| o.OnError(<br>#8<br>);                                                                                                  |
| }<br>}                                                                                                                  |
| }                                                                                                                       |
|                                                                                                                         |

| エラー: 93%、<br>\_exception: 7%                              |
| ----------------------------------------------------------- |
| エラー: 98%、<br>\_exception: 2%                              |
| \_gate: 100%、<br>\_observers: 0%                            |
| \_isStopped: 86%、<br>\_isDisposed: 13%、<br>HasObservers: 1% |
| \_isStopped: 91%、<br>\_isDisposed: 9%、<br>HasObservers: 0%  |
| \_exception: 100%、<br>エラー: 0%                             |
| エラー: 98%、<br>\_exception: 2%                              |
| \_exception: 99%、<br>エラー: 1%                              |
|                                                             |

. モデルは、最後以外のすべてのスロットから正しい変数を予測します。最後のスロットについて推論するには、クラスファイル全体にわたるコードの手続きをまたいだ理解が必要です。

#4 判定: 98%、削除要請: 2%

#### Sample 6

![](_page_13_Figure_2.jpeg)

#5 応答：98%、メッセージ：2%。モデルは、スロット#3のものを除き、すべての使用例を正しく予測しています。このスニペットについて推論するには、コードの意図に関するさらなるセマンティックな情報が必要です。

## Sample 7

![](_page_13_Figure_5.jpeg)

. モデルは、正しい文字列パラメータを選択する方法を知っています。なぜなら、それらを正式なパラメータ名と照合しているからです。

#### Sample 8

![](_page_13_Figure_8.jpeg)

モデルが条件文、特にスロット #2 のような珍しい定数を含む場合について推論するのは難しいです。

## <span id="page-14-0"></span>C NEAREST NEIGHBOR OF GGNN USAGE REPRESENTATIONS

ここでは、学習された表現 u(t, v) のコサイン類似度に基づく最も近いペアの例を示します。各スロット t は濃い青色で表示され、v のすべての使用箇所は黄色（つまり variableName ）で示されています。これは、良い例と悪い例の両方を示す手作業で選んだサンプルです。各ペアの後に簡単な説明が続きます。

#### Sample 1

![](_page_14_Figure_4.jpeg)

```
if ( unobservableExceptionHanler != null)
      return false;
   unobservableExceptionHanler = handler;
}
...
```

. nullであるかどうかをチェックされるスロットは、同様の表現を持っています。

#### Sample 2

```
...
public IActorRef ResolveActorRef(ActorPath actorPath ){
 if(HasAddress( actorPath .Address))
   return _local.ResolveActorRef(RootGuardian, actorPath .ElementsWithUid);
 ...
...
```

```
...
ActorPath actorPath ;
if (TryParseCachedPath(path, out actorPath)) {
   if (HasAddress( actorPath .Address)){
      if ( actorPath .ToStringWithoutAddress().Equals("/"))
         return RootGuarding;
      ...
   }
   ...
}
...
```

. 同様のAPIプロトコルに従うスロットは、類似した表現を持ちます。関数HasAddressはローカル関数であり、testset内でのみ確認できます。

#### Sample 3

```
...
foreach(var filter in configuration.Filters){
   GlobalJobFilter.Filters.Add( filter );
}
...
```

```
...
public void Count_ReturnsNumberOfElements(){
   _collection.Add( _filterInstance );
   Assert.Equal(1, _collection.Count);
}
...
```

コレクションのようなオブジェクトに要素を追加すると、同様の表現が得られます。

### <span id="page-15-0"></span>D DATASET

収集されたデータセットとその特徴は[Table 4.](#page-15-1) に示されています。全データセットはプロジェクトの集合および解析済みのJSONとしてオンラインで公開される予定です。

<span id="page-15-1"></span>Table 4: 私たちのデータセットに含まれるプロジェクト。アルファベット順に並んでいます。kLOCは、空行を除いたC#コードの行数を示します。Devと記載されたプロジェクトは開発セットとして使用されました。†と記載されたプロジェクトはテスト専用のデータセットに含まれています。その他のプロジェクトは、トレイン・バリデーション・テストに分割されました。データセット全体で約2.9MLOCが含まれています。

| Name              | Git SHA  | kLOCs | Slots | Vars  | Description                                 |     |
| ----------------- | -------- | ----- | ----- | ----- | ------------------------------------------- | --- |
| Akka.NET          | 719335a1 | 240   | 51.3k | 51.2k | アクターベースの並行・分散処理フレームワーク |     |
|                   |          |       |       |       | フレームワーク                               |     |
| AutoMapper        | 2ca7c2b5 | 46    | 3.7k  | 10.7k | オブジェクト間マッピングライブラリ            |     |
| BenchmarkDotNet   | 1670ca34 | 28    | 5.1k  | 6.1k  | ベンチマークライブラリ                        |     |
| BotBuilder        | 190117c3 | 44    | 6.4k  | 8.7k  | Bot構築用SDK                                |     |
| choco             | 93985688 | 36    | 3.8k  | 5.2k  | Windows向けパッケージマネージャー             |     |
| commandline†      | 09677b16 | 11    | 1.1k  | 2.3k  | コマンドラインパーサー                        |     |
| CommonMark.NETDev | f3d54530 | 14    | 2.6k  | 1.4k  | Markdownパーサー                             |     |
| Dapper            | 931c700d | 18    | 3.3k  | 4.7k  | オブジェクトマッピング用ライブラリ            |     |
| EntityFramework   | fa0b7ec8 | 263   | 33.4k | 39.3k | オブジェクト・リレーショナルマッパー           |     |
| Hangfire          | ffc4912f | 33    | 3.6k  | 6.1k  | バックグラウンドジョブ処理ライブラリ           |     |
| Humanizer†        | cc11a77e | 27    | 2.4k  | 4.4k  | 文字列操作とフォーマット用ライブラリ            |     |
| Lean†             | f574bfd7 | 190   | 26.4k | 28.3k | アルゴリズムによるトレーディングエンジン         |     |
| Nancy             | 72e1f614 | 70    | 7.5k  | 15.7  | HTTPサービス向けフレームワーク                 |     |
| Newtonsoft.Json   | 6057d9b8 | 123   | 14.9k | 16.1k | JSON処理用ライブラリ                          |     |
| Ninject           | 7006297f | 13    | 0.7k  | 2.1k  | コードインジェクション用ライブラリ              |     |
| NLog              | 643e326a | 75    | 8.3k  | 11.0k | ロギング用ライブラリ                          |     |
| Opserver          | 51b032e7 | 24    | 3.7k  | 4.5k  | 監視システム                                  |     |
| OptiKey           | 7d35c718 | 34    | 6.1k  | 3.9k  | 支援用オンスクリーンキーボード                 |     |
| orleans           | e0d6a150 | 300   | 30.7k | 35.6k | 分散型仮想アクターモデル                       |     |
| Polly             | 0afdbc32 | 32    | 3.8k  | 9.1k  | レジリエンスおよび一時的な障害からの回復処理用   |     |
|                   |          |       |       |       | ライブラリ                                     |     |
| quartznet         | b33e6f86 | 49    | 9.6k  | 9.8k  | スケジューラー                                 |     |
| ravendbDev        | 55230922 | 647   | 78.0k | 82.7k | ドキュメントデータベース                        |     |
| RestSharp         | 70de357b | 20    | 4.0k  | 4.5k  | REST・HTTP APIクライアントライブラリ             |     |
| Rx.NET            | 2d146fe5 | 180   | 14.0k | 21.9k | リアクティブ言語拡張機能                       |     |
| scriptcs          | f3cc8bcb | 18    | 2.7k  | 4.3k  | C#テキストエディタ                              |     |
| ServiceStack      | 6d59da75 | 231   | 38.0k | 46.2k | Webフレームワーク                               |     |
| ShareX            | 718dd711 | 125   | 22.3k | 18.1k | 共有アプリケーション                            |     |
| SignalR           | fa88089e | 53    | 6.5k  | 10.5k | プッシュ通知フレームワーク                      |     |
| Wox               | cdaf6272 | 13    | 2.0k  | 2.1k  | アプリケーションランチャー                       |     |

本研究のために、GPLライセンスを持つプロジェクトを除き、大部分のデータを公開しました。データは <https://aka.ms/iclr18-prog-graphs-dataset> で入手できます。一部のプロジェクトをデータから除外しているため、以下に公開済みのデータセットにおける三回の実行の平均結果を報告します。

|                | Accuracy (%) | PR AUC |
| -------------- | ------------ | ------ |
| SEENPROJTEST   | 84.0         | 0.976  |
| UNSEENPROJTEST | 74.1         | 0.934  |
